<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/BinEgo-360/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/BinEgo-360/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/BinEgo-360/iccv-hawaii-logo.svg"/><link rel="preload" as="image" href="/BinEgo-360/speakers/addison.png"/><link rel="preload" as="image" href="/BinEgo-360/speakers/dima.png"/><link rel="preload" as="image" href="/BinEgo-360/speakers/bernard.jpg"/><link rel="preload" as="image" href="https://x360dataset.github.io/static/images/overall.gif"/><link rel="preload" as="image" href="/BinEgo-360/organizers/jiao.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/wu.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/campbell.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/wei.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/qi.jpg"/><link rel="stylesheet" href="/BinEgo-360/_next/static/css/24bc4f8e4e79e833.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/BinEgo-360/_next/static/chunks/webpack-3ac31fac96870146.js"/><script src="/BinEgo-360/_next/static/chunks/4bd1b696-67ee12fb04071d3b.js" async=""></script><script src="/BinEgo-360/_next/static/chunks/684-8da6a75fa71dc898.js" async=""></script><script src="/BinEgo-360/_next/static/chunks/main-app-552d8ebf7c822fe1.js" async=""></script><link rel="preload" as="image" href="/BinEgo-360/organizers/placeholder_female.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/leonardis.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/chenyuan.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/han.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/qiming.jpg"/><link rel="preload" as="image" href="/BinEgo-360/organizers/hao.jpg"/><link rel="preload" as="image" href="/BinEgo-360/insta360-logo.png"/><link rel="preload" as="image" href="/BinEgo-360/SCAN-logo.png"/><link rel="preload" as="image" href="/BinEgo-360/allsee-logo.jpg"/><link rel="preload" as="image" href="/BinEgo-360/tencent_logo.png"/><meta name="next-size-adjust" content=""/><title>BinEgoâ€‘360 Challenge</title><meta name="description" content="The BinEgoâ€‘360 Challenge targets humanâ€‘like perception by jointly reasoning over 360Â° panoramic and binocular egocentric video streams, aligned with spatial audio, text and geoâ€‘metadata."/><link rel="icon" href="/BinEgo-360/favicon.ico" type="image/x-icon" sizes="256x256"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/BinEgo-360/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_6cccb2 __variable_a3dd79 antialiased"><header class="fixed inset-x-0 top-0 z-50 bg-white/80 backdrop-blur-md shadow-sm"><div class="flex items-center gap-6 bg-gray-800 px-4 py-1 text-xs text-gray-100"><div class="flex items-center gap-1"><svg class="h-4 w-4" fill="currentColor" viewBox="0 0 24 24"><path d="M12 2a7 7 0 00-7 7c0 5.25 7 13 7 13s7-7.75 7-13a7 7 0 00-7-7zm0 9.5a2.5 2.5 0 112.5-2.5 2.503 2.503 0 01-2.5 2.5z"></path></svg>Room 306 B, Hawaii Convention Center, Honolulu HI, USA</div><div class="flex items-center gap-1"><svg class="h-4 w-4" fill="currentColor" viewBox="0 0 24 24"><path d="M17 12a5 5 0 01-5 5v5h-3v-5a5 5 0 110-10V2h3v5a5 5 0 015 5z"></path></svg>19th Oct, 2025</div><a href="mailto:j.jiao@bham.ac.uk" class="hover:underline">j.jiao@bham.ac.uk</a></div><nav class="mx-auto flex max-w-7xl items-center justify-between px-4 py-3 text-sm font-medium text-gray-700"><div class="flex items-center gap-2 text-base font-semibold"><span class="text-indigo-600">BinEgoâ€‘360Â°</span><span>WorkshopÂ @Â ICCVÂ 2025</span></div><ul class="hidden gap-6 md:flex"><li><a href="#home" class="hover:text-indigo-600">Home</a></li><li><a href="#overview" class="hover:text-indigo-600">Overview</a></li><li><a href="#speakers" class="hover:text-indigo-600">Speakers</a></li><li><a href="#programme" class="hover:text-indigo-600">Programme</a></li><li><a href="#invited-papers" class="hover:text-indigo-600">Paper Presentations</a></li><li><a href="#challenge" class="hover:text-indigo-600">Challenge</a></li><li><a href="#organizers" class="hover:text-indigo-600">Organizers</a></li><li><a href="#sponsors" class="hover:text-indigo-600">Sponsors</a></li></ul></nav></header><main id="home" class="pt-24 pb-16"><section class="relative flex items-center justify-center text-center min-h-[540px] bg-cover bg-center bg-no-repeat" style="background-image:url(/BinEgo-360/hawaii-hero.jpg)"><div class="absolute inset-0 bg-black/60"></div><div class="relative z-10 mx-auto max-w-5xl px-4"><img src="/BinEgo-360/iccv-hawaii-logo.svg" alt="ICCV 2025 Honolulu Hawaii" class="mx-auto mb-6 h-20 w-auto"/><h1 class="text-4xl sm:text-5xl font-extrabold tracking-tight text-white">BinEgoâ€‘360Â°: Binocular Egocentric-360Â° Multi-modal Scene Understanding in the Wild</h1><p class="mx-auto mt-6 max-w-3xl text-lg text-gray-200">Welcome to the <span class="font-semibold text-indigo-200">BinEgoâ€‘360Â° Workshop &amp; Challenge</span> at ICCV 2025. We bring together researchers working on<!-- --> <strong>360Â° panoramic</strong> and <strong>binocular egocentric</strong> vision to explore humanâ€‘like perception across <em>video</em>, <em>audio</em>, and <em>geoâ€‘spatial</em> <!-- -->modalities.</p><div class="mt-10 flex flex-wrap justify-center gap-4"><a href="https://media.eventhosts.cc/Conferences/ICCV2025/iccv25_workshops_tutorials.pdf#page=40" target="_blank" rel="noreferrer" class="inline-flex items-center gap-2 rounded-full bg-indigo-600 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-400 focus:ring-offset-2"><svg class="h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 21s-7-4.686-7-11a7 7 0 1 1 14 0c0 6.314-7 11-7 11zm0-9.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5z"></path></svg>Venue: RoomÂ 306B</a><a href="https://iccv.thecvf.com/virtual/2025/workshop/2749" target="_blank" rel="noreferrer" class="inline-flex items-center gap-2 rounded-full bg-emerald-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-emerald-600 focus:outline-none focus:ring-2 focus:ring-emerald-300 focus:ring-offset-2"><svg class="h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 9V5.25A2.25 2.25 0 0 0 13.5 3h-9A2.25 2.25 0 0 0 2.25 5.25v13.5A2.25 2.25 0 0 0 4.5 21h9a2.25 2.25 0 0 0 2.25-2.25V15l6 3.75V5.25L15.75 9z"></path></svg>Join online</a><a href="#programme" class="inline-flex items-center gap-2 rounded-full border border-white/70 bg-white/90 px-6 py-3 text-sm font-semibold text-gray-900 shadow-lg transition hover:bg-white focus:outline-none focus:ring-2 focus:ring-white focus:ring-offset-2"><svg class="h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M8.25 6.75h7.5m-7.5 3h7.5m-7.5 3h4.5M6.75 5.25A2.25 2.25 0 0 0 4.5 7.5v9A2.25 2.25 0 0 0 6.75 18.75h10.5A2.25 2.25 0 0 0 19.5 16.5v-9a2.25 2.25 0 0 0-2.25-2.25H6.75z"></path></svg>View programme</a><a href="#challenge" class="inline-flex items-center gap-2 rounded-full bg-amber-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-amber-600 focus:outline-none focus:ring-2 focus:ring-amber-300 focus:ring-offset-2"><svg class="h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M16.5 3.75h2.25A1.25 1.25 0 0 1 20 5v2.25a3.75 3.75 0 0 1-3.75 3.75L16 11.5a4.5 4.5 0 0 1-3.75 3.7V18h2.25a.75.75 0 1 1 0 1.5H9.5A.75.75 0 1 1 9.5 18H11v-2.8A4.5 4.5 0 0 1 7.25 11.5l-.25-.5A3.75 3.75 0 0 1 3.25 7.25V5a1.25 1.25 0 0 1 1.25-1.25H6.75a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75H15a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75Z"></path></svg>Participate in challenge</a></div></div></section><section id="overview" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Overview</h2><p class="mt-6 text-gray-700">This half-day workshop mainly looks at multi-modal scene understanding and perception in a human-like way. Specifically, we will focus on <strong>binocular/stereo</strong> egocentric and <strong>360Â° panoramic</strong> perspectives, which measure both first-person views and third-person panoptic views, mimicking a human in the scene, by combining with multiâ€‘modal cues such as <em>spatial audio</em>, <em>textual descriptions</em>, and<!-- --> <em>geoâ€‘metadata</em>. This workshop will cover but not be limited to the following topics:</p><ul class="mt-4 list-disc space-y-2 pl-6 text-gray-700"><li>Embodied 360Â° scene understanding &amp; egocentric visual reasoning</li><li>Multi-modal scene understanding</li><li>Stereo Vision</li><li>Openâ€‘world learning &amp; domain adaptation</li></ul></section><section id="speakers" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Keynote Speakers</h2><div class="mt-8 grid gap-8 md:grid-cols-3"><div class="text-center"><a href="https://vlislab22.github.io/vlislab/linwang.html" target="_blank" rel="noreferrer"><img src="/BinEgo-360/speakers/addison.png" alt="Addison Lin Wang" class="mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-lg font-semibold text-gray-900"><a href="https://vlislab22.github.io/vlislab/linwang.html" target="_blank" rel="noreferrer" class="hover:underline">Addison Lin Wang</a></h3><p class="text-sm text-gray-600">Nanyang Technological University</p></div><div class="text-center"><a href="https://dimadamen.github.io/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/speakers/dima.png" alt="Dima Damen" class="mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-lg font-semibold text-gray-900"><a href="https://dimadamen.github.io/" target="_blank" rel="noreferrer" class="hover:underline">Dima Damen</a></h3><p class="text-sm text-gray-600">University of Bristol</p></div><div class="text-center"><a href="https://www.bernardghanem.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/speakers/bernard.jpg" alt="Bernard Ghanem" class="mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-lg font-semibold text-gray-900"><a href="https://www.bernardghanem.com/" target="_blank" rel="noreferrer" class="hover:underline">Bernard Ghanem</a></h3><p class="text-sm text-gray-600">King Abdullah University of Science and Technology</p></div></div></section><section id="programme" class="mx-auto mt-24 max-w-6xl px-4 lg:max-w-7xl"><div class="rounded-3xl bg-white/95 p-8 shadow-2xl ring-1 ring-indigo-100 backdrop-blur-sm"><div class="flex flex-col gap-4 sm:flex-row sm:items-center sm:justify-between"><h2 class="text-4xl font-extrabold tracking-tight text-gray-900">Workshop Programme (Halfâ€‘day)</h2><span class="inline-flex items-center gap-2 self-start rounded-full bg-indigo-600/10 px-4 py-2 text-sm font-semibold text-indigo-700 ring-1 ring-indigo-200"><svg class="h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M8.25 6.75h7.5M8.25 10.5h7.5m-7.5 3.75h4.5m7.5-1.5A2.25 2.25 0 0 1 19.5 18v1.5A2.25 2.25 0 0 1 17.25 21H6.75A2.25 2.25 0 0 1 4.5 18.75V18a2.25 2.25 0 0 1 2.25-2.25h12.75Zm0-9.75V6A2.25 2.25 0 0 1 19.5 8.25H4.5A2.25 2.25 0 0 1 2.25 6V4.5A2.25 2.25 0 0 1 4.5 2.25h15A2.25 2.25 0 0 1 21.75 4.5V6Z"></path></svg>RoomÂ 306B Â· 19Â OctÂ 2025</span></div><div class="mt-6 overflow-x-auto"><table class="w-full min-w-[640px] text-left text-base text-gray-900"><thead class="bg-indigo-600/90 text-white"><tr><th class="whitespace-nowrap px-6 py-3 text-lg font-semibold tracking-wide">Time</th><th class="px-6 py-3 text-lg font-semibold tracking-wide">Session</th></tr></thead><tbody class="divide-y divide-indigo-100"><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">09:00 â€“ 09:30</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><span class="font-semibold text-gray-900">Opening Remarks</span></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">09:30 â€“ 10:05</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><div class="flex flex-wrap items-center gap-3"><span class="inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800"><span class="rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700">Keynote</span>Bernard Ghanem â€” Towards Robust Multimodal Egocentric Video Understanding</span><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Slides available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</button><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">10:05 â€“ 10:40</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><div class="flex flex-wrap items-center gap-3"><span class="inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800"><span class="rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700">Keynote</span>Dima Damen â€” Video Understanding Out of the Frame: An Egocentric Perspective</span><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><a href="/BinEgo-360/pdfs/Ego360-ICCV2025-Workshop-DimaDamen.pdf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</a><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">10:40 â€“ 11:00</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><span class="font-semibold text-gray-900">Break &amp; Poster Session</span></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">11:00 â€“ 11:45</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><div class="space-y-4 text-sm text-gray-700 md:text-base"><span class="rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700">Invited Paper Presentations</span><ul class="space-y-1 leading-relaxed"><li class="space-y-1"><div class="flex flex-wrap items-center gap-2"><a href="https://red-fairy.github.io/argus/" target="_blank" rel="noopener noreferrer" class="font-semibold text-amber-700 hover:text-amber-800 hover:underline">Beyond the Frame: Generating 360Â° Panoramic Videos from Perspective Videos</a><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><a href="/BinEgo-360/pdfs/iccv_presentation_RundongLuo.pdf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</a><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div><div class="text-sm italic text-gray-600 md:text-base">Presenter: Rundong Luo</div></li><li class="space-y-1"><div class="flex flex-wrap items-center gap-2"><a href="https://schowdhury671.github.io/egoadapt_project/" target="_blank" rel="noopener noreferrer" class="font-semibold text-amber-700 hover:text-amber-800 hover:underline">EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception</a><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><a href="/BinEgo-360/pdfs/%5BInvitedPaperPresentation%5D%20EgoAdapt%20-%20BinEgo360.pdf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</a><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div><div class="text-sm italic text-gray-600 md:text-base">Presenter: Sanjoy Chowdhury</div></li><li class="space-y-1"><div class="flex flex-wrap items-center gap-2"><a href="https://vision.cs.utexas.edu/projects/switch_a_view/" target="_blank" rel="noopener noreferrer" class="font-semibold text-amber-700 hover:text-amber-800 hover:underline">Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos</a><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><a href="/BinEgo-360/pdfs/%5BInvitedPaperPresentation%5D%20binEgoICCV_sagnikMajumder.pdf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</a><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div><div class="text-sm italic text-gray-600 md:text-base">Presenter: Sagnik Majumder</div></li></ul></div></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">11:45 â€“ 12:20</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><div class="flex flex-wrap items-center gap-3"><span class="inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800"><span class="rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700">Keynote</span>Addison Lin Wang â€” 360 Vision in the Foundation AI Era: Principles, Methods, and Future Directions</span><div class="flex flex-wrap items-center gap-2 text-xs font-semibold"><a href="/BinEgo-360/pdfs/360-vision%20in%20foundation%20AI%20era-ICCV2025%20-%20Addison%20Wang.pdf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path></svg>Slides</a><button type="button" class="inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500" title="Available soon" aria-label="Recording available soon"><svg class="h-3.5 w-3.5" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"></circle><path d="M10 9l5 3-5 3V9z"></path></svg>Recording</button></div></div></div></td></tr><tr class="odd:bg-white even:bg-indigo-50/40 align-top"><td class="whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700">12:20 â€“ 12:35</td><td class="px-6 py-4 align-top text-base text-gray-900"><div class="space-y-4"><span class="font-semibold text-gray-900">Awards Ceremony &amp; Concluding Remarks</span></div></td></tr></tbody></table></div></div></section><section id="challenge" class="mx-auto mt-24 max-w-6xl px-4"><h2 class="text-3xl font-bold text-gray-900">BinEgoâ€‘360Â° Challenge</h2><p class="mt-6 text-gray-700">The challenge uses our public dataset <a href="https://x360dataset.github.io/" target="_blank" rel="noreferrer" class="underline">360+x</a> for training/validation, and a held-out test set for the evaluation. <ul>Apart from the prizes, winners of the challenge will be invited to submit a paper/report to be included in the workshop proceedings and present at the workshop.</ul> For more details about the dataset, tracks, timeline, and submission rules, please see below:</p><div class="mt-6 rounded border-l-4 border-yellow-400 bg-yellow-50 p-4 text-gray-700"><p class="font-semibold">Important Notice:</p><p class="mt-2"><b>New Final Submission DeadlineÂ Â â–¶Â Â 20 August 2025 (AOE)</b></p><p class="mt-2">We are delighted to let you know that the challenge deadline has been extended! Now you have more time to cook your good stuff!</p></div></section><section id="dataset" class="mx-auto mt-24 max-w-6xl px-4"><h2 class="text-3xl font-bold text-gray-900">Dataset Overview</h2><div class="mt-8 grid gap-8 md:grid-cols-2"><div class="w-full h-[400px] overflow-hidden rounded-lg shadow-md"><img src="https://x360dataset.github.io/static/images/overall.gif" alt="Dataset montage" class="w-full h-full object-cover"/></div><div class="flex flex-col justify-center text-gray-700"><ul class="space-y-3"><li>2,152 videos â€“ 8.579 M frames / 67.78 h.</li><li><strong>Viewpoints</strong>: 360Â° panoramic, binocular &amp; monocular egocentric, thirdâ€‘person front.</li><li><strong>Modalities</strong>: RGB video, 6â€‘channel spatial audio, GPS + weather, text scene description.</li><li><strong>Annotations</strong>: 38 action classes, temporal segments; object bounding boxes.</li><li><strong>Resolution</strong>: 5 K originals (5 760 Ã— 2 880 pano).</li><li><strong>License</strong>: CC BYâ€‘NCâ€‘SA 4.0. All faces autoâ€‘blurred.</li></ul><div class="mt-6 flex flex-wrap gap-4"><a href="https://huggingface.co/datasets/quchenyuan/360x_dataset_HR" class="rounded bg-gray-800 px-4 py-2 text-sm font-medium text-white hover:bg-gray-900">Download HR</a><a href="https://huggingface.co/datasets/quchenyuan/360x_dataset_LR" class="rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400">Download LR</a><a href="https://arxiv.org/abs/2404.00989" class="rounded border border-indigo-600 bg-indigo-50 px-4 py-2 text-sm font-medium text-indigo-700 hover:bg-indigo-100">Paper (CVPR 2024)</a><a href="https://github.com/x360dataset/x360dataset-kit" class="rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400">Baseline Code</a></div></div></div></section><section id="tracks" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Challenge Tracks &amp; Baselines</h2><div class="mt-10 grid gap-20 md:grid-cols-2"><div class="flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm"><div><h3 class="text-xl font-semibold text-indigo-600">1 Â· Classification</h3><p class="mt-2 text-gray-600">Predict the scene label for a whole clip. We follow the scene categories provided in the dataset.</p><ul class="mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700"><li><strong>Input</strong>: 360Â° RGB + egocentric RGB + audio/binaural delay.</li><li><strong>Output</strong>: The scene label.</li><li><strong>Metric</strong>: Topâ€‘1 Accuracy (in test set).</li></ul></div><div class="mt-6 rounded bg-gray-50 p-4 text-sm"><p class="font-medium">Baseline (All views and modalities use)</p><p>Topâ€‘1 Acc: <span class="font-semibold">80.62  %</span></p></div><div class="mt-8 text-center"><a href="https://www.kaggle.com/competitions/bin-ego-360-challenge-classification-ext" target="_blank" rel="noreferrer" class="inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="h-5 w-5" fill="currentColor"><path d="M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z"></path></svg>JoinÂ onÂ Kaggle</a></div></div><div class="flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm"><div><h3 class="text-xl font-semibold text-indigo-600">2 Â· Temporal Action Localization</h3><p class="mt-2 text-gray-600">Detect the start and end time of every action instance inside a clip.</p><ul class="mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700"><li><strong>Input</strong>: Same modalities as Track 1</li><li><strong>Output</strong>: JSON output for each detection:<code>{&quot;video_id&quot;: ..., &quot;t_start&quot;: ..., &quot;t_end&quot;: ..., &quot;label&quot;: ...}</code></li><li><strong>Metric</strong>: mAP averaged over IoU âˆˆ <!-- -->{0.5, 0.75, 0.95}<!-- -->.</li></ul></div><div class="mt-6 rounded bg-gray-50 p-4 text-sm"><p class="font-medium mb-2">Baseline (TriDet + VAD)</p><table class="w-full text-sm text-left text-gray-700 border border-gray-200 rounded"><thead class="bg-gray-100"><tr><th class="px-3 py-2 border-b">Metric</th><th class="px-3 py-2 border-b">Score</th></tr></thead><tbody><tr><td class="px-3 py-2 border-b">mAP@0.5</td><td class="px-3 py-2 border-b font-semibold">27.1</td></tr><tr><td class="px-3 py-2 border-b">mAP@0.75</td><td class="px-3 py-2 border-b font-semibold">18.7</td></tr><tr><td class="px-3 py-2 border-b">mAP@0.95</td><td class="px-3 py-2 border-b font-semibold">7.0</td></tr><tr><td class="px-3 py-2">Average</td><td class="px-3 py-2 font-semibold">17.6</td></tr></tbody></table></div><div class="mt-8 text-center"><a href="https://www.kaggle.com/competitions/bin-ego-360-challenge-tal-ext" target="_blank" rel="noreferrer" class="inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="h-5 w-5" fill="currentColor"><path d="M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z"></path></svg>JoinÂ onÂ Kaggle</a></div></div></div><div class="mt-10 space-y-6"><h3 class="text-2xl font-semibold text-gray-900">ğŸ† Competition Winners</h3><p class="text-gray-700">Congratulations to the teams whose solutions topped the CLS and TAL tracks of the BinEgo-360 Challenge. Explore the podium finishers and their affiliations below.</p><div class="grid gap-6 md:grid-cols-2"><div class="rounded-lg border border-gray-200 p-6 shadow-sm"><h4 class="text-xl font-semibold text-gray-900">CLS Track</h4><ol class="mt-4 space-y-4 text-gray-700"><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">1st Place</p><p>Xudong Cao, Lei Hei, Xudong Wang, and Liangqu Long</p><p class="text-sm text-gray-600">Corresponding Author: Liangqu Long</p><p class="text-sm text-gray-600">Team: Insta360 ML2</p></li><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">2nd Place</p><p>Rishav Sanjay</p><p class="text-sm text-gray-600">RV University Bengaluru</p><p class="text-sm text-gray-600">Team: EigenAdapt</p></li><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">3rd Place</p><p>Paul Ngâ€™angâ€™a Kamau</p><p class="text-sm text-gray-600">Kenyatta University &amp; Moringa School</p></li></ol></div><div class="rounded-lg border border-gray-200 p-6 shadow-sm"><h4 class="text-xl font-semibold text-gray-900">TAL Track</h4><ol class="mt-4 space-y-4 text-gray-700"><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">1st Place</p><p>Duong Anh Kiet and Petra Gomez-KrÃ¤mer</p><p class="text-sm text-gray-600">L3i Laboratory, La Rochelle University</p><p class="text-sm text-gray-600">Team: L3I</p></li><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">2nd Place</p><p>Paul Ngâ€™angâ€™a Kamau</p><p class="text-sm text-gray-600">Kenyatta University &amp; Moringa School</p></li><li class="rounded-md bg-gray-50 p-4"><p class="text-lg font-semibold text-gray-900">3rd Place</p><p>Chan U Wang é™³è£•å¼˜</p><p class="text-sm text-gray-600">University of Macau</p></li></ol></div></div></div></section><section id="timeline" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Timeline (Anywhere on Earth)</h2><ol class="mt-8 border-l-2 border-indigo-600"><li class="relative ml-6 pb-8 last:pb-0"><span class="absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"></span><span class="font-medium text-gray-900">1 Jun 2025</span><span class="ml-2 text-gray-600">Dataset &amp; baselines release; Kaggle opens</span></li><li class="relative ml-6 pb-8 last:pb-0"><span class="absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"></span><span class="font-medium text-gray-900">20 Aug 2025</span><span class="ml-2 text-gray-600">Submission deadline</span></li><li class="relative ml-6 pb-8 last:pb-0"><span class="absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"></span><span class="font-medium text-gray-900">Sep 2025</span><span class="ml-2 text-gray-600">Technical report and poster due</span></li><li class="relative ml-6 pb-8 last:pb-0"><span class="absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"></span><span class="font-medium text-gray-900">19-20 Oct 2025</span><span class="ml-2 text-gray-600">Awards &amp; talks at ICCV 2025 workshop</span></li></ol></section><section id="submission" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Submission Rules</h2><ol class="mt-6 list-decimal space-y-3 pl-6 text-gray-700"><li>Teams (â‰¤  5 members) register on Kaggle and fill in the team form.</li><li>Up to <strong>5 submissions per track per team</strong> â€“ the last one counts.</li><li>The winners need to submit a technical report and a poster to be presented at the workshop</li><li>No external data that overlaps with the hidden test clips.</li><li>Any submission after the deadline will not be considered.</li></ol></section><section id="prizes" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Prizes &amp; Sponsors</h2><ul class="mt-6 space-y-2 text-gray-700"><li><strong>1st Place:</strong> <!-- -->Insta360 X5 camera (<a href="https://www.insta360.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Insta360</a>) + Workshop registration (<a href="https://www.tencent.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Tencent</a>) + Â£10k Cloud GPU credit (<a href="https://www.scan.co.uk/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">SCAN</a>)</li><li><strong>2nd Place:</strong> <!-- -->Â£10k Cloud GPU credit (<a href="https://www.scan.co.uk/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">SCAN</a>) + Workshop registration (<a href="https://www.tencent.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Tencent</a>) + Â£100 voucher (<a href="https://www.allsee-tech.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Allsee</a>)</li><li><strong>3rd Place:</strong> <!-- -->Â£5k Cloud GPU credit (<a href="https://www.scan.co.uk/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">SCAN</a>) + Â£50 voucher (<a href="https://www.allsee-tech.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Allsee</a>)</li></ul><p class="mt-4 text-gray-700">Sponsored by <a href="https://www.insta360.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Insta360</a> Â· <a href="https://www.scan.co.uk/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">SCAN</a> Â· <a href="https://www.allsee-tech.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Allsee</a> Â· <a href="https://www.tencent.com/" target="_blank" rel="noreferrer" class="text-indigo-600 hover:underline">Tencent</a></p></section><section class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Ethics &amp; Broader Impact</h2><p class="mt-4 text-gray-700">All videos were recorded in public or nonâ€‘sensitive areas with informed participant consent. Faces are automatically blurred, and the dataset is released for nonâ€‘commercial research under CC BYâ€‘NCâ€‘SA 4.0. We prohibit any reâ€‘identification, surveillance or commercial use. By advancing robust multiâ€‘modal perception, we aim to benefit robotics, AR/VR and assistive tech while upholding fairness and privacy.</p></section><section id="organizers" class="mx-auto mt-24 max-w-4xl px-4"><h2 class="text-3xl font-bold text-gray-900">Organisers</h2><div class="mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4"><div class="text-center"><a href="https://jianbojiao.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/jiao.jpg" alt="Jianbo Jiao" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://jianbojiao.com/" target="_blank" rel="noreferrer" class="hover:underline">Jianbo Jiao</a></h3><p class="text-sm text-gray-600">University of Birmingham</p></div><div class="text-center"><a href="https://elliottwu.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/wu.jpg" alt="ShangzheÂ Wu" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://elliottwu.com/" target="_blank" rel="noreferrer" class="hover:underline">ShangzheÂ Wu</a></h3><p class="text-sm text-gray-600">University of Cambridge</p></div><div class="text-center"><a href="https://sites.google.com/view/djcampbell" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/campbell.jpg" alt="DylanÂ Campbell" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://sites.google.com/view/djcampbell" target="_blank" rel="noreferrer" class="hover:underline">DylanÂ Campbell</a></h3><p class="text-sm text-gray-600">Australian National University</p></div><div class="text-center"><a href="https://weiyc.github.io/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/wei.jpg" alt="YunchaoÂ Wei" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://weiyc.github.io/" target="_blank" rel="noreferrer" class="hover:underline">YunchaoÂ Wei</a></h3><p class="text-sm text-gray-600">Beijing Jiaotong University</p></div><div class="text-center"><a href="http://luqi.info/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/qi.jpg" alt="LuÂ Qi" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="http://luqi.info/" target="_blank" rel="noreferrer" class="hover:underline">LuÂ Qi</a></h3><p class="text-sm text-gray-600">Insta360</p></div><div class="text-center"><a href="https://www.audioscenic.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/placeholder_female.jpg" alt="YasmineÂ Mellah" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://www.audioscenic.com/" target="_blank" rel="noreferrer" class="hover:underline">YasmineÂ Mellah</a></h3><p class="text-sm text-gray-600">Audioscenic</p></div><div class="text-center"><a href="https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/leonardis.jpg" alt="AleÅ¡Â Leonardis" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales" target="_blank" rel="noreferrer" class="hover:underline">AleÅ¡Â Leonardis</a></h3><p class="text-sm text-gray-600">University of Birmingham</p></div></div><p class="mt-8 text-gray-700"><span class="font-semibold">Technical Committee:</span></p><div class="mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4"><div class="text-center"><a href="https://chenyuanqu.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/chenyuan.jpg" alt="Chenyuan Qu" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://chenyuanqu.com/" target="_blank" rel="noreferrer" class="hover:underline">Chenyuan Qu</a></h3><p class="text-sm text-gray-600">University of Birmingham</p></div><div class="text-center"><a href="https://scholar.google.com/Publicationss?hl=zh-CN&amp;view_op=list_works&amp;gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4&amp;user=UJRtTJ0AAAAJ" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/han.jpg" alt="Han Hu" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://scholar.google.com/Publicationss?hl=zh-CN&amp;view_op=list_works&amp;gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4&amp;user=UJRtTJ0AAAAJ" target="_blank" rel="noreferrer" class="hover:underline">Han Hu</a></h3><p class="text-sm text-gray-600">University of Birmingham</p></div><div class="text-center"><a href="https://qiming-huang.github.io/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/qiming.jpg" alt="Qiming Huang" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://qiming-huang.github.io/" target="_blank" rel="noreferrer" class="hover:underline">Qiming Huang</a></h3><p class="text-sm text-gray-600">University of Birmingham</p></div><div class="text-center"><a href="https://h-chen.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/organizers/hao.jpg" alt="Hao Chen" class="mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"/></a><h3 class="mt-3 text-base font-semibold text-gray-900"><a href="https://h-chen.com/" target="_blank" rel="noreferrer" class="hover:underline">Hao Chen</a></h3><p class="text-sm text-gray-600">University of Cambridge</p></div></div><p class="mt-4 text-gray-700">Contact: <a href="mailto:j.jiao@bham.ac.uk" class="text-indigo-600 hover:underline">j.jiao@bham.ac.uk</a></p></section><section id="sponsors" class="mx-auto mt-24 max-w-10xl px-4 text-center"><h2 class="text-3xl font-bold text-gray-900">Sponsors</h2><p class="mt-6 text-gray-700">We gratefully acknowledge the generous support of our sponsors.</p><div class="mt-10 flex flex-wrap justify-center gap-10"><a href="https://www.insta360.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/insta360-logo.png" alt="Insta360" class="h-24 object-contain"/></a><a href="https://www.scan.co.uk/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/SCAN-logo.png" alt="SCAN" class="h-24 object-contain"/></a><a href="https://www.allsee-tech.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/allsee-logo.jpg" alt="Allsee" class="h-24 object-contain"/></a><a href="https://www.tencent.com/" target="_blank" rel="noreferrer"><img src="/BinEgo-360/tencent_logo.png" alt="Tencent" class="h-24 object-contain"/></a></div></section><section class="mx-auto mt-24 max-w-3xl px-4"><h2 class="text-3xl font-bold text-gray-900">Publication(s)</h2><p class="mt-4 text-gray-700">If you use the 360+x dataset or participate in the challenge, please consider cite:</p><pre class="mt-4 rounded bg-gray-100 p-4 text-sm leading-tight text-gray-800 overflow-x-auto">@inproceedings{chen2024x360,
  title     = {360+x: A Panoptic Multi-modal Scene Understanding Dataset},
  author    = {Chen, Hao and Hou, Yuqi and Qu, Chenyuan and Testini, Irene and Hong, Xiaohan and Jiao, Jianbo},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2024}
}</pre></section><footer class="mt-32 bg-gray-50 py-6 text-center text-sm text-gray-600"><p>Â© <!-- -->2025<!-- --> BinEgoâ€‘360Â° Workshop. Built with Next.js &amp; Tailwind CSS. Hosted on GitHub Pages.</p></footer></main><!--$--><!--/$--><!--$--><!--/$--><script src="/BinEgo-360/_next/static/chunks/webpack-3ac31fac96870146.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[9665,[],\"MetadataBoundary\"]\n6:I[9665,[],\"OutletBoundary\"]\n9:I[4911,[],\"AsyncMetadataOutlet\"]\nb:I[9665,[],\"ViewportBoundary\"]\nd:I[6614,[],\"\"]\n:HL[\"/BinEgo-360/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/BinEgo-360/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/BinEgo-360/_next/static/css/24bc4f8e4e79e833.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"St9Lv6-ec_UC3QSXsQgzH\",\"p\":\"/BinEgo-360\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/BinEgo-360/_next/static/css/24bc4f8e4e79e833.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_6cccb2 __variable_a3dd79 antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[null,[\"$\",\"header\",null,{\"className\":\"fixed inset-x-0 top-0 z-50 bg-white/80 backdrop-blur-md shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-6 bg-gray-800 px-4 py-1 text-xs text-gray-100\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"d\":\"M12 2a7 7 0 00-7 7c0 5.25 7 13 7 13s7-7.75 7-13a7 7 0 00-7-7zm0 9.5a2.5 2.5 0 112.5-2.5 2.503 2.503 0 01-2.5 2.5z\"}]}],\"Room 306 B, Hawaii Convention Center, Honolulu HI, USA\"]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"d\":\"M17 12a5 5 0 01-5 5v5h-3v-5a5 5 0 110-10V2h3v5a5 5 0 015 5z\"}]}],\"19th Oct, 2025\"]}],[\"$\",\"a\",null,{\"href\":\"mailto:j.jiao@bham.ac.uk\",\"className\":\"hover:underline\",\"children\":\"j.jiao@bham.ac.uk\"}]]}],[\"$\",\"nav\",null,{\"className\":\"mx-auto flex max-w-7xl items-center justify-between px-4 py-3 text-sm font-medium text-gray-700\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2 text-base font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-indigo-600\",\"children\":\"BinEgoâ€‘360Â°\"}],[\"$\",\"span\",null,{\"children\":\"WorkshopÂ @Â ICCVÂ 2025\"}]]}],[\"$\",\"ul\",null,{\"className\":\"hidden gap-6 md:flex\",\"children\":[[\"$\",\"li\",\"#home\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#home\",\"className\":\"hover:text-indigo-600\",\"children\":\"Home\"}]}],[\"$\",\"li\",\"#overview\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#overview\",\"className\":\"hover:text-indigo-600\",\"children\":\"Overview\"}]}],[\"$\",\"li\",\"#speakers\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#speakers\",\"className\":\"hover:text-indigo-600\",\"children\":\"Speakers\"}]}],[\"$\",\"li\",\"#programme\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#programme\",\"className\":\"hover:text-indigo-600\",\"children\":\"Programme\"}]}],[\"$\",\"li\",\"#invited-papers\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#invited-papers\",\"className\":\"hover:text-indigo-600\",\"children\":\"Paper Presentations\"}]}],[\"$\",\"li\",\"#challenge\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#challenge\",\"className\":\"hover:text-indigo-600\",\"children\":\"Challenge\"}]}],[\"$\",\"li\",\"#organizers\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#organizers\",\"className\":\"hover:text-indigo-600\",\"children\":\"Organizers\"}]}],[\"$\",\"li\",\"#sponsors\",{\"children\":[\"$\",\"a\",null,{\"href\":\"#sponsors\",\"className\":\"hover:text-indigo-600\",\"children\":\"Sponsors\"}]}]]}]]}]]}],[\"$\",\"main\",null,{\"id\":\"home\",\"className\":\"pt-24 pb-16\",\"children\":[[\"$\",\"section\",null,{\"className\":\"relative flex items-center justify-center text-center min-h-[540px] bg-cover bg-center bg-no-repeat\",\"style\":{\"backgroundImage\":\"url(/BinEgo-360/hawaii-hero.jpg)\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute inset-0 bg-black/60\"}],[\"$\",\"div\",null,{\"className\":\"relative z-10 mx-auto max-w-5xl px-4\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/iccv-hawaii-logo.svg\",\"alt\":\"ICCV 2025 Honolulu Hawaii\",\"className\":\"mx-auto mb-6 h-20 w-auto\"}],[\"$\",\"h1\",null,{\"className\":\"text-4xl sm:text-5xl font-extrabold tracking-tight text-white\",\"children\":\"BinEgoâ€‘360Â°: Binocular Egocentric-360Â° Multi-modal Scene Understanding in the Wild\"}],[\"$\",\"p\",null,{\"className\":\"mx-auto mt-6 max-w-3xl text-lg text-gray-200\",\"children\":[\"Welcome to the \",[\"$\",\"span\",null,{\"className\":\"font-semibold text-indigo-200\",\"children\":\"BinEgoâ€‘360Â° Workshop \u0026 Challenge\"}],\" at ICCV 2025. We bring together researchers working on\",\" \",[\"$\",\"strong\",null,{\"children\":\"360Â° panoramic\"}],\" and \",[\"$\",\"strong\",null,{\"children\":\"binocular egocentric\"}],\" vision to explore humanâ€‘like perception across \",[\"$\",\"em\",null,{\"children\":\"video\"}],\", \",[\"$\",\"em\",null,{\"children\":\"audio\"}],\", and \",[\"$\",\"em\",null,{\"children\":\"geoâ€‘spatial\"}],\" \",\"modalities.\"]}],[\"$\",\"div\",null,{\"className\":\"mt-10 flex flex-wrap justify-center gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://media.eventhosts.cc/Conferences/ICCV2025/iccv25_workshops_tutorials.pdf#page=40\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-full bg-indigo-600 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-400 focus:ring-offset-2\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M12 21s-7-4.686-7-11a7 7 0 1 1 14 0c0 6.314-7 11-7 11zm0-9.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5z\"}]}],\"Venue: RoomÂ 306B\"]}],[\"$\",\"a\",null,{\"href\":\"https://iccv.thecvf.com/virtual/2025/workshop/2749\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-full bg-emerald-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-emerald-600 focus:outline-none focus:ring-2 focus:ring-emerald-300 focus:ring-offset-2\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M15.75 9V5.25A2.25 2.25 0 0 0 13.5 3h-9A2.25 2.25 0 0 0 2.25 5.25v13.5A2.25 2.25 0 0 0 4.5 21h9a2.25 2.25 0 0 0 2.25-2.25V15l6 3.75V5.25L15.75 9z\"}]}],\"Join online\"]}],[\"$\",\"a\",null,{\"href\":\"#programme\",\"className\":\"inline-flex items-center gap-2 rounded-full border border-white/70 bg-white/90 px-6 py-3 text-sm font-semibold text-gray-900 shadow-lg transition hover:bg-white focus:outline-none focus:ring-2 focus:ring-white focus:ring-offset-2\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M8.25 6.75h7.5m-7.5 3h7.5m-7.5 3h4.5M6.75 5.25A2.25 2.25 0 0 0 4.5 7.5v9A2.25 2.25 0 0 0 6.75 18.75h10.5A2.25 2.25 0 0 0 19.5 16.5v-9a2.25 2.25 0 0 0-2.25-2.25H6.75z\"}]}],\"View programme\"]}],[\"$\",\"a\",null,{\"href\":\"#challenge\",\"className\":\"inline-flex items-center gap-2 rounded-full bg-amber-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-amber-600 focus:outline-none focus:ring-2 focus:ring-amber-300 focus:ring-offset-2\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M16.5 3.75h2.25A1.25 1.25 0 0 1 20 5v2.25a3.75 3.75 0 0 1-3.75 3.75L16 11.5a4.5 4.5 0 0 1-3.75 3.7V18h2.25a.75.75 0 1 1 0 1.5H9.5A.75.75 0 1 1 9.5 18H11v-2.8A4.5 4.5 0 0 1 7.25 11.5l-.25-.5A3.75 3.75 0 0 1 3.25 7.25V5a1.25 1.25 0 0 1 1.25-1.25H6.75a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75H15a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75Z\"}]}],\"Participate in challenge\"]}]]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"overview\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Overview\"}],[\"$\",\"p\",null,{\"className\":\"mt-6 text-gray-700\",\"children\":[\"This half-day workshop mainly looks at multi-modal scene understanding and perception in a human-like way. Specifically, we will focus on \",[\"$\",\"strong\",null,{\"children\":\"binocular/stereo\"}],\" egocentric and \",[\"$\",\"strong\",null,{\"children\":\"360Â° panoramic\"}],\" perspectives, which measure both first-person views and third-person panoptic views, mimicking a human in the scene, by combining with multiâ€‘modal cues such as \",[\"$\",\"em\",null,{\"children\":\"spatial audio\"}],\", \",[\"$\",\"em\",null,{\"children\":\"textual descriptions\"}],\", and\",\" \",[\"$\",\"em\",null,{\"children\":\"geoâ€‘metadata\"}],\". This workshop will cover but not be limited to the following topics:\"]}],[\"$\",\"ul\",null,{\"className\":\"mt-4 list-disc space-y-2 pl-6 text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Embodied 360Â° scene understanding \u0026 egocentric visual reasoning\"}],[\"$\",\"li\",null,{\"children\":\"Multi-modal scene understanding\"}],[\"$\",\"li\",null,{\"children\":\"Stereo Vision\"}],[\"$\",\"li\",null,{\"children\":\"Openâ€‘world learning \u0026 domain adaptation\"}]]}]]}],[\"$\",\"section\",null,{\"id\":\"speakers\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Keynote Speakers\"}],[\"$\",\"div\",null,{\"className\":\"mt-8 grid gap-8 md:grid-cols-3\",\"children\":[[\"$\",\"div\",\"Addison Lin Wang\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://vlislab22.github.io/vlislab/linwang.html\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/speakers/addison.png\",\"alt\":\"Addison Lin Wang\",\"className\":\"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-lg font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://vlislab22.github.io/vlislab/linwang.html\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Addison Lin Wang\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Nanyang Technological University\"}]]}],[\"$\",\"div\",\"Dima Damen\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://dimadamen.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/speakers/dima.png\",\"alt\":\"Dima Damen\",\"className\":\"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-lg font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://dimadamen.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Dima Damen\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Bristol\"}]]}],[\"$\",\"div\",\"Bernard Ghanem\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.bernardghanem.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/speakers/bernard.jpg\",\"alt\":\"Bernard Ghanem\",\"className\":\"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-lg font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.bernardghanem.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Bernard Ghanem\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"King Abdullah University of Science and Technology\"}]]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"programme\",\"className\":\"mx-auto mt-24 max-w-6xl px-4 lg:max-w-7xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-3xl bg-white/95 p-8 shadow-2xl ring-1 ring-indigo-100 backdrop-blur-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-4 sm:flex-row sm:items-center sm:justify-between\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-4xl font-extrabold tracking-tight text-gray-900\",\"children\":\"Workshop Programme (Halfâ€‘day)\"}],[\"$\",\"span\",null,{\"className\":\"inline-flex items-center gap-2 self-start rounded-full bg-indigo-600/10 px-4 py-2 text-sm font-semibold text-indigo-700 ring-1 ring-indigo-200\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-4 w-4\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M8.25 6.75h7.5M8.25 10.5h7.5m-7.5 3.75h4.5m7.5-1.5A2.25 2.25 0 0 1 19.5 18v1.5A2.25 2.25 0 0 1 17.25 21H6.75A2.25 2.25 0 0 1 4.5 18.75V18a2.25 2.25 0 0 1 2.25-2.25h12.75Zm0-9.75V6A2.25 2.25 0 0 1 19.5 8.25H4.5A2.25 2.25 0 0 1 2.25 6V4.5A2.25 2.25 0 0 1 4.5 2.25h15A2.25 2.25 0 0 1 21.75 4.5V6Z\"}]}],\"RoomÂ 306B Â· 19Â OctÂ 2025\"]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-6 overflow-x-auto\",\"children\":[\"$\",\"table\",null,{\"className\":\"w-full min-w-[640px] text-left text-base text-gray-900\",\"children\":[[\"$\",\"thead\",null,{\"className\":\"bg-indigo-600/90 text-white\",\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"className\":\"whitespace-nowrap px-6 py-3 text-lg font-semibold tracking-wide\",\"children\":\"Time\"}],[\"$\",\"th\",null,{\"className\":\"px-6 py-3 text-lg font-semibold tracking-wide\",\"children\":\"Session\"}]]}]}],[\"$\",\"tbody\",null,{\"className\":\"divide-y divide-indigo-100\",\"children\":[[\"$\",\"tr\",\"0\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"09:00 â€“ 09:30\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold text-gray-900\",\"children\":\"Opening Remarks\"}],false]}]}]]}],[\"$\",\"tr\",\"1\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"09:30 â€“ 10:05\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700\",\"children\":\"Keynote\"}],\"Bernard Ghanem â€” Towards Robust Multimodal Egocentric Video Understanding\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Slides available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],false]}]}]]}],[\"$\",\"tr\",\"2\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"10:05 â€“ 10:40\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700\",\"children\":\"Keynote\"}],\"Dima Damen â€” Video Understanding Out of the Frame: An Egocentric Perspective\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/BinEgo-360/pdfs/Ego360-ICCV2025-Workshop-DimaDamen.pdf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],false]}]}]]}],[\"$\",\"tr\",\"3\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"10:40 â€“ 11:00\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold text-gray-900\",\"children\":\"Break \u0026 Poster Session\"}],false]}]}]]}],[\"$\",\"tr\",\"4\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"11:00 â€“ 11:45\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[false,[\"$\",\"div\",null,{\"className\":\"space-y-4 text-sm text-gray-700 md:text-base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700\",\"children\":\"Invited Paper Presentations\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 leading-relaxed\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"space-y-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://red-fairy.github.io/argus/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"font-semibold text-amber-700 hover:text-amber-800 hover:underline\",\"children\":\"Beyond the Frame: Generating 360Â° Panoramic Videos from Perspective Videos\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/BinEgo-360/pdfs/iccv_presentation_RundongLuo.pdf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-gray-600 md:text-base\",\"children\":\"Presenter: Rundong Luo\"}]]}],[\"$\",\"li\",\"1\",{\"className\":\"space-y-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://schowdhury671.github.io/egoadapt_project/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"font-semibold text-amber-700 hover:text-amber-800 hover:underline\",\"children\":\"EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/BinEgo-360/pdfs/%5BInvitedPaperPresentation%5D%20EgoAdapt%20-%20BinEgo360.pdf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-gray-600 md:text-base\",\"children\":\"Presenter: Sanjoy Chowdhury\"}]]}],[\"$\",\"li\",\"2\",{\"className\":\"space-y-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://vision.cs.utexas.edu/projects/switch_a_view/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"font-semibold text-amber-700 hover:text-amber-800 hover:underline\",\"children\":\"Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/BinEgo-360/pdfs/%5BInvitedPaperPresentation%5D%20binEgoICCV_sagnikMajumder.pdf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-gray-600 md:text-base\",\"children\":\"Presenter: Sagnik Majumder\"}]]}]]}]]}]]}]}]]}],[\"$\",\"tr\",\"5\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"11:45 â€“ 12:20\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3\",\"children\":[[\"$\",\"span\",null,{\"className\":\"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800\",\"children\":[[\"$\",\"span\",null,{\"className\":\"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700\",\"children\":\"Keynote\"}],\"Addison Lin Wang â€” 360 Vision in the Foundation AI Era: Principles, Methods, and Future Directions\"]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-2 text-xs font-semibold\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/BinEgo-360/pdfs/360-vision%20in%20foundation%20AI%20era-ICCV2025%20-%20Addison%20Wang.pdf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 rounded-full border border-indigo-200 px-3 py-1 text-indigo-700 transition hover:bg-indigo-50\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M6 2h9l5 5v13a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z\"}],[\"$\",\"path\",null,{\"d\":\"M14 2v4a2 2 0 0 0 2 2h4\"}]]}],\"Slides\"]}],[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"inline-flex cursor-not-allowed items-center gap-1 rounded-full border border-dashed border-gray-300 px-3 py-1 text-gray-500\",\"title\":\"Available soon\",\"aria-label\":\"Recording available soon\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"h-3.5 w-3.5\",\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":\"1.5\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"children\":[[\"$\",\"circle\",null,{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"9\"}],[\"$\",\"path\",null,{\"d\":\"M10 9l5 3-5 3V9z\"}]]}],\"Recording\"]}]]}]]}],false]}]}]]}],[\"$\",\"tr\",\"6\",{\"className\":\"odd:bg-white even:bg-indigo-50/40 align-top\",\"children\":[[\"$\",\"td\",null,{\"className\":\"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700\",\"children\":\"12:20 â€“ 12:35\"}],[\"$\",\"td\",null,{\"className\":\"px-6 py-4 align-top text-base text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold text-gray-900\",\"children\":\"Awards Ceremony \u0026 Concluding Remarks\"}],false]}]}]]}]]}]]}]}]]}]}],[\"$\",\"section\",null,{\"id\":\"challenge\",\"className\":\"mx-auto mt-24 max-w-6xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"BinEgoâ€‘360Â° Challenge\"}],[\"$\",\"p\",null,{\"className\":\"mt-6 text-gray-700\",\"children\":[\"The challenge uses our public dataset \",[\"$\",\"a\",null,{\"href\":\"https://x360dataset.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"underline\",\"children\":\"360+x\"}],\" for training/validation, and a held-out test set for the evaluation. \",[\"$\",\"ul\",null,{\"children\":\"Apart from the prizes, winners of the challenge will be invited to submit a paper/report to be included in the workshop proceedings and present at the workshop.\"}],\" For more details about the dataset, tracks, timeline, and submission rules, please see below:\"]}],[\"$\",\"div\",null,{\"className\":\"mt-6 rounded border-l-4 border-yellow-400 bg-yellow-50 p-4 text-gray-700\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-semibold\",\"children\":\"Important Notice:\"}],[\"$\",\"p\",null,{\"className\":\"mt-2\",\"children\":[\"$\",\"b\",null,{\"children\":\"New Final Submission DeadlineÂ Â â–¶Â Â 20 August 2025 (AOE)\"}]}],[\"$\",\"p\",null,{\"className\":\"mt-2\",\"children\":\"We are delighted to let you know that the challenge deadline has been extended! Now you have more time to cook your good stuff!\"}]]}]]}],[\"$\",\"section\",null,{\"id\":\"dataset\",\"className\":\"mx-auto mt-24 max-w-6xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Dataset Overview\"}],[\"$\",\"div\",null,{\"className\":\"mt-8 grid gap-8 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full h-[400px] overflow-hidden rounded-lg shadow-md\",\"children\":[\"$\",\"img\",null,{\"src\":\"https://x360dataset.github.io/static/images/overall.gif\",\"alt\":\"Dataset montage\",\"className\":\"w-full h-full object-cover\"}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col justify-center text-gray-700\",\"children\":[[\"$\",\"ul\",null,{\"className\":\"space-y-3\",\"children\":[[\"$\",\"li\",null,{\"children\":\"2,152 videos â€“ 8.579 M frames / 67.78 h.\"}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Viewpoints\"}],\": 360Â° panoramic, binocular \u0026 monocular egocentric, thirdâ€‘person front.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Modalities\"}],\": RGB video, 6â€‘channel spatial audio, GPS + weather, text scene description.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Annotations\"}],\": 38 action classes, temporal segments; object bounding boxes.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Resolution\"}],\": 5 K originals (5 760 Ã— 2 880 pano).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"License\"}],\": CC BYâ€‘NCâ€‘SA 4.0. All faces autoâ€‘blurred.\"]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-6 flex flex-wrap gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/datasets/quchenyuan/360x_dataset_HR\",\"className\":\"rounded bg-gray-800 px-4 py-2 text-sm font-medium text-white hover:bg-gray-900\",\"children\":\"Download HR\"}],[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/datasets/quchenyuan/360x_dataset_LR\",\"className\":\"rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400\",\"children\":\"Download LR\"}],[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2404.00989\",\"className\":\"rounded border border-indigo-600 bg-indigo-50 px-4 py-2 text-sm font-medium text-indigo-700 hover:bg-indigo-100\",\"children\":\"Paper (CVPR 2024)\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/x360dataset/x360dataset-kit\",\"className\":\"rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400\",\"children\":\"Baseline Code\"}]]}]]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"tracks\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Challenge Tracks \u0026 Baselines\"}],[\"$\",\"div\",null,{\"className\":\"mt-10 grid gap-20 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold text-indigo-600\",\"children\":\"1 Â· Classification\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-gray-600\",\"children\":\"Predict the scene label for a whole clip. We follow the scene categories provided in the dataset.\"}],[\"$\",\"ul\",null,{\"className\":\"mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Input\"}],\": 360Â° RGB + egocentric RGB + audio/binaural delay.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Output\"}],\": The scene label.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Metric\"}],\": Topâ€‘1 Accuracy (in test set).\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-6 rounded bg-gray-50 p-4 text-sm\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium\",\"children\":\"Baseline (All views and modalities use)\"}],[\"$\",\"p\",null,{\"children\":[\"Topâ€‘1 Acc: \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"80.62  %\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 text-center\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.kaggle.com/competitions/bin-ego-360-challenge-classification-ext\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 24 24\",\"className\":\"h-5 w-5\",\"fill\":\"currentColor\",\"children\":[\"$\",\"path\",null,{\"d\":\"M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z\"}]}],\"JoinÂ onÂ Kaggle\"]}]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-semibold text-indigo-600\",\"children\":\"2 Â· Temporal Action Localization\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-gray-600\",\"children\":\"Detect the start and end time of every action instance inside a clip.\"}],[\"$\",\"ul\",null,{\"className\":\"mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Input\"}],\": Same modalities as Track 1\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Output\"}],\": JSON output for each detection:\",[\"$\",\"code\",null,{\"children\":\"{\\\"video_id\\\": ..., \\\"t_start\\\": ..., \\\"t_end\\\": ..., \\\"label\\\": ...}\"}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Metric\"}],\": mAP averaged over IoU âˆˆ \",\"{0.5, 0.75, 0.95}\",\".\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-6 rounded bg-gray-50 p-4 text-sm\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium mb-2\",\"children\":\"Baseline (TriDet + VAD)\"}],[\"$\",\"table\",null,{\"className\":\"w-full text-sm text-left text-gray-700 border border-gray-200 rounded\",\"children\":[[\"$\",\"thead\",null,{\"className\":\"bg-gray-100\",\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"className\":\"px-3 py-2 border-b\",\"children\":\"Metric\"}],[\"$\",\"th\",null,{\"className\":\"px-3 py-2 border-b\",\"children\":\"Score\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b\",\"children\":\"mAP@0.5\"}],[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b font-semibold\",\"children\":\"27.1\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b\",\"children\":\"mAP@0.75\"}],[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b font-semibold\",\"children\":\"18.7\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b\",\"children\":\"mAP@0.95\"}],[\"$\",\"td\",null,{\"className\":\"px-3 py-2 border-b font-semibold\",\"children\":\"7.0\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"px-3 py-2\",\"children\":\"Average\"}],[\"$\",\"td\",null,{\"className\":\"px-3 py-2 font-semibold\",\"children\":\"17.6\"}]]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 text-center\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.kaggle.com/competitions/bin-ego-360-challenge-tal-ext\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 24 24\",\"className\":\"h-5 w-5\",\"fill\":\"currentColor\",\"children\":[\"$\",\"path\",null,{\"d\":\"M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z\"}]}],\"JoinÂ onÂ Kaggle\"]}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-10 space-y-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-semibold text-gray-900\",\"children\":\"ğŸ† Competition Winners\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700\",\"children\":\"Congratulations to the teams whose solutions topped the CLS and TAL tracks of the BinEgo-360 Challenge. Explore the podium finishers and their affiliations below.\"}],[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"rounded-lg border border-gray-200 p-6 shadow-sm\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold text-gray-900\",\"children\":\"CLS Track\"}],[\"$\",\"ol\",null,{\"className\":\"mt-4 space-y-4 text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"1st Place\"}],[\"$\",\"p\",null,{\"children\":\"Xudong Cao, Lei Hei, Xudong Wang, and Liangqu Long\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Corresponding Author: Liangqu Long\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Team: Insta360 ML2\"}]]}],[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"2nd Place\"}],[\"$\",\"p\",null,{\"children\":\"Rishav Sanjay\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"RV University Bengaluru\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Team: EigenAdapt\"}]]}],[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"3rd Place\"}],[\"$\",\"p\",null,{\"children\":\"Paul Ngâ€™angâ€™a Kamau\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Kenyatta University \u0026 Moringa School\"}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"rounded-lg border border-gray-200 p-6 shadow-sm\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold text-gray-900\",\"children\":\"TAL Track\"}],[\"$\",\"ol\",null,{\"className\":\"mt-4 space-y-4 text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"1st Place\"}],[\"$\",\"p\",null,{\"children\":\"Duong Anh Kiet and Petra Gomez-KrÃ¤mer\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"L3i Laboratory, La Rochelle University\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Team: L3I\"}]]}],[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"2nd Place\"}],[\"$\",\"p\",null,{\"children\":\"Paul Ngâ€™angâ€™a Kamau\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Kenyatta University \u0026 Moringa School\"}]]}],[\"$\",\"li\",null,{\"className\":\"rounded-md bg-gray-50 p-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-lg font-semibold text-gray-900\",\"children\":\"3rd Place\"}],[\"$\",\"p\",null,{\"children\":\"Chan U Wang é™³è£•å¼˜\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Macau\"}]]}]]}]]}]]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"timeline\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Timeline (Anywhere on Earth)\"}],[\"$\",\"ol\",null,{\"className\":\"mt-8 border-l-2 border-indigo-600\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"relative ml-6 pb-8 last:pb-0\",\"children\":[[\"$\",\"span\",null,{\"className\":\"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900\",\"children\":\"1 Jun 2025\"}],[\"$\",\"span\",null,{\"className\":\"ml-2 text-gray-600\",\"children\":\"Dataset \u0026 baselines release; Kaggle opens\"}]]}],[\"$\",\"li\",\"1\",{\"className\":\"relative ml-6 pb-8 last:pb-0\",\"children\":[[\"$\",\"span\",null,{\"className\":\"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900\",\"children\":\"20 Aug 2025\"}],[\"$\",\"span\",null,{\"className\":\"ml-2 text-gray-600\",\"children\":\"Submission deadline\"}]]}],[\"$\",\"li\",\"2\",{\"className\":\"relative ml-6 pb-8 last:pb-0\",\"children\":[[\"$\",\"span\",null,{\"className\":\"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900\",\"children\":\"Sep 2025\"}],[\"$\",\"span\",null,{\"className\":\"ml-2 text-gray-600\",\"children\":\"Technical report and poster due\"}]]}],[\"$\",\"li\",\"3\",{\"className\":\"relative ml-6 pb-8 last:pb-0\",\"children\":[[\"$\",\"span\",null,{\"className\":\"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900\",\"children\":\"19-20 Oct 2025\"}],[\"$\",\"span\",null,{\"className\":\"ml-2 text-gray-600\",\"children\":\"Awards \u0026 talks at ICCV 2025 workshop\"}]]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"submission\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Submission Rules\"}],[\"$\",\"ol\",null,{\"className\":\"mt-6 list-decimal space-y-3 pl-6 text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Teams (â‰¤  5 members) register on Kaggle and fill in the team form.\"}],[\"$\",\"li\",null,{\"children\":[\"Up to \",[\"$\",\"strong\",null,{\"children\":\"5 submissions per track per team\"}],\" â€“ the last one counts.\"]}],[\"$\",\"li\",null,{\"children\":\"The winners need to submit a technical report and a poster to be presented at the workshop\"}],[\"$\",\"li\",null,{\"children\":\"No external data that overlaps with the hidden test clips.\"}],[\"$\",\"li\",null,{\"children\":\"Any submission after the deadline will not be considered.\"}]]}]]}],[\"$\",\"section\",null,{\"id\":\"prizes\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Prizes \u0026 Sponsors\"}],[\"$\",\"ul\",null,{\"className\":\"mt-6 space-y-2 text-gray-700\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"1st Place:\"}],\" \",\"Insta360 X5 camera (\",[\"$\",\"a\",null,{\"href\":\"https://www.insta360.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Insta360\"}],\") + Workshop registration (\",[\"$\",\"a\",null,{\"href\":\"https://www.tencent.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Tencent\"}],\") + Â£10k Cloud GPU credit (\",[\"$\",\"a\",null,{\"href\":\"https://www.scan.co.uk/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"SCAN\"}],\")\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"2nd Place:\"}],\" \",\"Â£10k Cloud GPU credit (\",[\"$\",\"a\",null,{\"href\":\"https://www.scan.co.uk/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"SCAN\"}],\") + Workshop registration (\",[\"$\",\"a\",null,{\"href\":\"https://www.tencent.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Tencent\"}],\") + Â£100 voucher (\",[\"$\",\"a\",null,{\"href\":\"https://www.allsee-tech.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Allsee\"}],\")\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"3rd Place:\"}],\" \",\"Â£5k Cloud GPU credit (\",[\"$\",\"a\",null,{\"href\":\"https://www.scan.co.uk/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"SCAN\"}],\") + Â£50 voucher (\",[\"$\",\"a\",null,{\"href\":\"https://www.allsee-tech.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Allsee\"}],\")\"]}]]}],[\"$\",\"p\",null,{\"className\":\"mt-4 text-gray-700\",\"children\":[\"Sponsored by \",[\"$\",\"a\",null,{\"href\":\"https://www.insta360.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Insta360\"}],\" Â· \",[\"$\",\"a\",null,{\"href\":\"https://www.scan.co.uk/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"SCAN\"}],\" Â· \",[\"$\",\"a\",null,{\"href\":\"https://www.allsee-tech.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Allsee\"}],\" Â· \",[\"$\",\"a\",null,{\"href\":\"https://www.tencent.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"Tencent\"}]]}]]}],[\"$\",\"section\",null,{\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Ethics \u0026 Broader Impact\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 text-gray-700\",\"children\":\"All videos were recorded in public or nonâ€‘sensitive areas with informed participant consent. Faces are automatically blurred, and the dataset is released for nonâ€‘commercial research under CC BYâ€‘NCâ€‘SA 4.0. We prohibit any reâ€‘identification, surveillance or commercial use. By advancing robust multiâ€‘modal perception, we aim to benefit robotics, AR/VR and assistive tech while upholding fairness and privacy.\"}]]}],[\"$\",\"section\",null,{\"id\":\"organizers\",\"className\":\"mx-auto mt-24 max-w-4xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Organisers\"}],[\"$\",\"div\",null,{\"className\":\"mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4\",\"children\":[[\"$\",\"div\",\"Jianbo Jiao\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://jianbojiao.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/jiao.jpg\",\"alt\":\"Jianbo Jiao\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://jianbojiao.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Jianbo Jiao\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Birmingham\"}]]}],[\"$\",\"div\",\"ShangzheÂ Wu\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://elliottwu.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/wu.jpg\",\"alt\":\"ShangzheÂ Wu\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://elliottwu.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"ShangzheÂ Wu\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Cambridge\"}]]}],[\"$\",\"div\",\"DylanÂ Campbell\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://sites.google.com/view/djcampbell\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/campbell.jpg\",\"alt\":\"DylanÂ Campbell\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://sites.google.com/view/djcampbell\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"DylanÂ Campbell\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Australian National University\"}]]}],[\"$\",\"div\",\"YunchaoÂ Wei\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://weiyc.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/wei.jpg\",\"alt\":\"YunchaoÂ Wei\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://weiyc.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"YunchaoÂ Wei\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Beijing Jiaotong University\"}]]}],[\"$\",\"div\",\"LuÂ Qi\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"http://luqi.info/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/qi.jpg\",\"alt\":\"LuÂ Qi\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"http://luqi.info/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"LuÂ Qi\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Insta360\"}]]}],[\"$\",\"div\",\"YasmineÂ Mellah\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.audioscenic.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/placeholder_female.jpg\",\"alt\":\"YasmineÂ Mellah\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.audioscenic.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"YasmineÂ Mellah\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"Audioscenic\"}]]}],[\"$\",\"div\",\"AleÅ¡Â Leonardis\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/leonardis.jpg\",\"alt\":\"AleÅ¡Â Leonardis\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"AleÅ¡Â Leonardis\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Birmingham\"}]]}]]}],[\"$\",\"p\",null,{\"className\":\"mt-8 text-gray-700\",\"children\":[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"Technical Committee:\"}]}],[\"$\",\"div\",null,{\"className\":\"mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4\",\"children\":[[\"$\",\"div\",\"Chenyuan Qu\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://chenyuanqu.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/chenyuan.jpg\",\"alt\":\"Chenyuan Qu\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://chenyuanqu.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Chenyuan Qu\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Birmingham\"}]]}],[\"$\",\"div\",\"Han Hu\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://scholar.google.com/Publicationss?hl=zh-CN\u0026view_op=list_works\u0026gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4\u0026user=UJRtTJ0AAAAJ\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/han.jpg\",\"alt\":\"Han Hu\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://scholar.google.com/Publicationss?hl=zh-CN\u0026view_op=list_works\u0026gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4\u0026user=UJRtTJ0AAAAJ\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Han Hu\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Birmingham\"}]]}],[\"$\",\"div\",\"Qiming Huang\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://qiming-huang.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/qiming.jpg\",\"alt\":\"Qiming Huang\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://qiming-huang.github.io/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Qiming Huang\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Birmingham\"}]]}],[\"$\",\"div\",\"Hao Chen\",{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://h-chen.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/organizers/hao.jpg\",\"alt\":\"Hao Chen\",\"className\":\"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg\"}]}],[\"$\",\"h3\",null,{\"className\":\"mt-3 text-base font-semibold text-gray-900\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://h-chen.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"className\":\"hover:underline\",\"children\":\"Hao Chen\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":\"University of Cambridge\"}]]}]]}],[\"$\",\"p\",null,{\"className\":\"mt-4 text-gray-700\",\"children\":[\"Contact: \",[\"$\",\"a\",null,{\"href\":\"mailto:j.jiao@bham.ac.uk\",\"className\":\"text-indigo-600 hover:underline\",\"children\":\"j.jiao@bham.ac.uk\"}]]}]]}],[\"$\",\"section\",null,{\"id\":\"sponsors\",\"className\":\"mx-auto mt-24 max-w-10xl px-4 text-center\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Sponsors\"}],[\"$\",\"p\",null,{\"className\":\"mt-6 text-gray-700\",\"children\":\"We gratefully acknowledge the generous support of our sponsors.\"}],[\"$\",\"div\",null,{\"className\":\"mt-10 flex flex-wrap justify-center gap-10\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.insta360.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/insta360-logo.png\",\"alt\":\"Insta360\",\"className\":\"h-24 object-contain\"}]}],[\"$\",\"a\",null,{\"href\":\"https://www.scan.co.uk/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/SCAN-logo.png\",\"alt\":\"SCAN\",\"className\":\"h-24 object-contain\"}]}],[\"$\",\"a\",null,{\"href\":\"https://www.allsee-tech.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/allsee-logo.jpg\",\"alt\":\"Allsee\",\"className\":\"h-24 object-contain\"}]}],[\"$\",\"a\",null,{\"href\":\"https://www.tencent.com/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"img\",null,{\"src\":\"/BinEgo-360/tencent_logo.png\",\"alt\":\"Tencent\",\"className\":\"h-24 object-contain\"}]}]]}]]}],[\"$\",\"section\",null,{\"className\":\"mx-auto mt-24 max-w-3xl px-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Publication(s)\"}],[\"$\",\"p\",null,{\"className\":\"mt-4 text-gray-700\",\"children\":\"If you use the 360+x dataset or participate in the challenge, please consider cite:\"}],[\"$\",\"pre\",null,{\"className\":\"mt-4 rounded bg-gray-100 p-4 text-sm leading-tight text-gray-800 overflow-x-auto\",\"children\":\"@inproceedings{chen2024x360,\\n  title     = {360+x: A Panoptic Multi-modal Scene Understanding Dataset},\\n  author    = {Chen, Hao and Hou, Yuqi and Qu, Chenyuan and Testini, Irene and Hong, Xiaohan and Jiao, Jianbo},\\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\\n  year      = {2024}\\n}\"}]]}],[\"$\",\"footer\",null,{\"className\":\"mt-32 bg-gray-50 py-6 text-center text-sm text-gray-600\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Â© \",2025,\" BinEgoâ€‘360Â° Workshop. Built with Next.js \u0026 Tailwind CSS. Hosted on GitHub Pages.\"]}]}]]}]],[\"$\",\"$L4\",null,{\"children\":\"$L5\"}],null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"U19QbCT3dRU1gvH0RdAQj\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:\"$Sreact.suspense\"\nf:I[4911,[],\"AsyncMetadata\"]\n5:[\"$\",\"$e\",null,{\"fallback\":null,\"children\":[\"$\",\"$Lf\",null,{\"promise\":\"$@10\"}]}]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"10:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"BinEgoâ€‘360 Challenge\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"The BinEgoâ€‘360 Challenge targets humanâ€‘like perception by jointly reasoning over 360Â° panoramic and binocular egocentric video streams, aligned with spatial audio, text and geoâ€‘metadata.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/BinEgo-360/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}]],\"error\":null,\"digest\":\"$undefined\"}\na:{\"metadata\":\"$10:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>