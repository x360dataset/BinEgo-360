1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
4:I[9665,[],"MetadataBoundary"]
6:I[9665,[],"OutletBoundary"]
9:I[4911,[],"AsyncMetadataOutlet"]
b:I[9665,[],"ViewportBoundary"]
d:I[6614,[],""]
:HL["/BinEgo-360/_next/static/media/4cf2300e9c8272f7-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/BinEgo-360/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/BinEgo-360/_next/static/css/fdedd551e0217345.css","style"]
0:{"P":null,"b":"VKNFTk_Vt3yH05LE1J392","p":"/BinEgo-360","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/BinEgo-360/_next/static/css/fdedd551e0217345.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__variable_6cccb2 __variable_a3dd79 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[[null,["$","header",null,{"className":"fixed inset-x-0 top-0 z-50 bg-white/80 backdrop-blur-md shadow-sm","children":[["$","div",null,{"className":"flex items-center gap-6 bg-gray-800 px-4 py-1 text-xs text-gray-100","children":[["$","div",null,{"className":"flex items-center gap-1","children":[["$","svg",null,{"className":"h-4 w-4","fill":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"d":"M12 2a7 7 0 00-7 7c0 5.25 7 13 7 13s7-7.75 7-13a7 7 0 00-7-7zm0 9.5a2.5 2.5 0 112.5-2.5 2.503 2.503 0 01-2.5 2.5z"}]}],"Room 306 B, Hawaii Convention Center, Honolulu HI, USA"]}],["$","div",null,{"className":"flex items-center gap-1","children":[["$","svg",null,{"className":"h-4 w-4","fill":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"d":"M17 12a5 5 0 01-5 5v5h-3v-5a5 5 0 110-10V2h3v5a5 5 0 015 5z"}]}],"19th Oct, 2025"]}],["$","a",null,{"href":"mailto:j.jiao@bham.ac.uk","className":"hover:underline","children":"j.jiao@bham.ac.uk"}]]}],["$","nav",null,{"className":"mx-auto flex max-w-7xl items-center justify-between px-4 py-3 text-sm font-medium text-gray-700","children":[["$","div",null,{"className":"flex items-center gap-2 text-base font-semibold","children":[["$","span",null,{"className":"text-indigo-600","children":"BinEgo‑360°"}],["$","span",null,{"children":"Workshop @ ICCV 2025"}]]}],["$","ul",null,{"className":"hidden gap-6 md:flex","children":[["$","li","#home",{"children":["$","a",null,{"href":"#home","className":"hover:text-indigo-600","children":"Home"}]}],["$","li","#overview",{"children":["$","a",null,{"href":"#overview","className":"hover:text-indigo-600","children":"Overview"}]}],["$","li","#speakers",{"children":["$","a",null,{"href":"#speakers","className":"hover:text-indigo-600","children":"Speakers"}]}],["$","li","#programme",{"children":["$","a",null,{"href":"#programme","className":"hover:text-indigo-600","children":"Programme"}]}],["$","li","#invited-papers",{"children":["$","a",null,{"href":"#invited-papers","className":"hover:text-indigo-600","children":"Paper Presentations"}]}],["$","li","#challenge",{"children":["$","a",null,{"href":"#challenge","className":"hover:text-indigo-600","children":"Challenge"}]}],["$","li","#organizers",{"children":["$","a",null,{"href":"#organizers","className":"hover:text-indigo-600","children":"Organizers"}]}],["$","li","#sponsors",{"children":["$","a",null,{"href":"#sponsors","className":"hover:text-indigo-600","children":"Sponsors"}]}]]}]]}]]}],["$","main",null,{"id":"home","className":"pt-24 pb-16","children":[["$","section",null,{"className":"relative flex items-center justify-center text-center min-h-[540px] bg-cover bg-center bg-no-repeat","style":{"backgroundImage":"url(/BinEgo-360/hawaii-hero.jpg)"},"children":[["$","div",null,{"className":"absolute inset-0 bg-black/60"}],["$","div",null,{"className":"relative z-10 mx-auto max-w-5xl px-4","children":[["$","img",null,{"src":"/BinEgo-360/iccv-hawaii-logo.svg","alt":"ICCV 2025 Honolulu Hawaii","className":"mx-auto mb-6 h-20 w-auto"}],["$","h1",null,{"className":"text-4xl sm:text-5xl font-extrabold tracking-tight text-white","children":"BinEgo‑360°: Binocular Egocentric-360° Multi-modal Scene Understanding in the Wild"}],["$","p",null,{"className":"mx-auto mt-6 max-w-3xl text-lg text-gray-200","children":["Welcome to the ",["$","span",null,{"className":"font-semibold text-indigo-200","children":"BinEgo‑360° Workshop & Challenge"}]," at ICCV 2025. We bring together researchers working on"," ",["$","strong",null,{"children":"360° panoramic"}]," and ",["$","strong",null,{"children":"binocular egocentric"}]," vision to explore human‑like perception across ",["$","em",null,{"children":"video"}],", ",["$","em",null,{"children":"audio"}],", and ",["$","em",null,{"children":"geo‑spatial"}]," ","modalities."]}],["$","div",null,{"className":"mt-10 flex flex-wrap justify-center gap-4","children":[["$","a",null,{"href":"https://media.eventhosts.cc/Conferences/ICCV2025/iccv25_workshops_tutorials.pdf#page=40","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-2 rounded-full bg-indigo-600 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-400 focus:ring-offset-2","children":[["$","svg",null,{"className":"h-4 w-4","xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","strokeWidth":"1.5","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M12 21s-7-4.686-7-11a7 7 0 1 1 14 0c0 6.314-7 11-7 11zm0-9.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5z"}]}],"Venue: Room 306B"]}],["$","a",null,{"href":"https://iccv.thecvf.com/virtual/2025/workshop/2749","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-2 rounded-full bg-emerald-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-emerald-600 focus:outline-none focus:ring-2 focus:ring-emerald-300 focus:ring-offset-2","children":[["$","svg",null,{"className":"h-4 w-4","xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","strokeWidth":"1.5","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M15.75 9V5.25A2.25 2.25 0 0 0 13.5 3h-9A2.25 2.25 0 0 0 2.25 5.25v13.5A2.25 2.25 0 0 0 4.5 21h9a2.25 2.25 0 0 0 2.25-2.25V15l6 3.75V5.25L15.75 9z"}]}],"Join online"]}],["$","a",null,{"href":"#programme","className":"inline-flex items-center gap-2 rounded-full border border-white/70 bg-white/90 px-6 py-3 text-sm font-semibold text-gray-900 shadow-lg transition hover:bg-white focus:outline-none focus:ring-2 focus:ring-white focus:ring-offset-2","children":[["$","svg",null,{"className":"h-4 w-4","xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","strokeWidth":"1.5","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M8.25 6.75h7.5m-7.5 3h7.5m-7.5 3h4.5M6.75 5.25A2.25 2.25 0 0 0 4.5 7.5v9A2.25 2.25 0 0 0 6.75 18.75h10.5A2.25 2.25 0 0 0 19.5 16.5v-9a2.25 2.25 0 0 0-2.25-2.25H6.75z"}]}],"View programme"]}],["$","a",null,{"href":"#challenge","className":"inline-flex items-center gap-2 rounded-full bg-amber-500 px-6 py-3 text-sm font-semibold text-white shadow-lg transition hover:bg-amber-600 focus:outline-none focus:ring-2 focus:ring-amber-300 focus:ring-offset-2","children":[["$","svg",null,{"className":"h-4 w-4","xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","strokeWidth":"1.5","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M16.5 3.75h2.25A1.25 1.25 0 0 1 20 5v2.25a3.75 3.75 0 0 1-3.75 3.75L16 11.5a4.5 4.5 0 0 1-3.75 3.7V18h2.25a.75.75 0 1 1 0 1.5H9.5A.75.75 0 1 1 9.5 18H11v-2.8A4.5 4.5 0 0 1 7.25 11.5l-.25-.5A3.75 3.75 0 0 1 3.25 7.25V5a1.25 1.25 0 0 1 1.25-1.25H6.75a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75H15a.75.75 0 0 1 .75.75v4a2.25 2.25 0 1 0 4.5 0v-4a.75.75 0 0 1 .75-.75Z"}]}],"Participate in challenge"]}]]}]]}]]}],["$","section",null,{"id":"overview","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Overview"}],["$","p",null,{"className":"mt-6 text-gray-700","children":["This half-day workshop mainly looks at multi-modal scene understanding and perception in a human-like way. Specifically, we will focus on ",["$","strong",null,{"children":"binocular/stereo"}]," egocentric and ",["$","strong",null,{"children":"360° panoramic"}]," perspectives, which measure both first-person views and third-person panoptic views, mimicking a human in the scene, by combining with multi‑modal cues such as ",["$","em",null,{"children":"spatial audio"}],", ",["$","em",null,{"children":"textual descriptions"}],", and"," ",["$","em",null,{"children":"geo‑metadata"}],". This workshop will cover but not be limited to the following topics:"]}],["$","ul",null,{"className":"mt-4 list-disc space-y-2 pl-6 text-gray-700","children":[["$","li",null,{"children":"Embodied 360° scene understanding & egocentric visual reasoning"}],["$","li",null,{"children":"Multi-modal scene understanding"}],["$","li",null,{"children":"Stereo Vision"}],["$","li",null,{"children":"Open‑world learning & domain adaptation"}]]}]]}],["$","section",null,{"id":"speakers","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Keynote Speakers"}],["$","div",null,{"className":"mt-8 grid gap-8 md:grid-cols-3","children":[["$","div","Addison Lin Wang",{"className":"text-center","children":[["$","a",null,{"href":"https://vlislab22.github.io/vlislab/linwang.html","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/speakers/addison.png","alt":"Addison Lin Wang","className":"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-lg font-semibold text-gray-900","children":["$","a",null,{"href":"https://vlislab22.github.io/vlislab/linwang.html","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Addison Lin Wang"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"Nanyang Technological University"}]]}],["$","div","Dima Damen",{"className":"text-center","children":[["$","a",null,{"href":"https://dimadamen.github.io/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/speakers/dima.png","alt":"Dima Damen","className":"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-lg font-semibold text-gray-900","children":["$","a",null,{"href":"https://dimadamen.github.io/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Dima Damen"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Bristol"}]]}],["$","div","Bernard Ghanem",{"className":"text-center","children":[["$","a",null,{"href":"https://www.bernardghanem.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/speakers/bernard.jpg","alt":"Bernard Ghanem","className":"mx-auto h-36 w-36 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-lg font-semibold text-gray-900","children":["$","a",null,{"href":"https://www.bernardghanem.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Bernard Ghanem"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"King Abdullah University of Science and Technology"}]]}]]}]]}],["$","section",null,{"id":"programme","className":"mx-auto mt-24 max-w-6xl px-4 lg:max-w-7xl","children":["$","div",null,{"className":"rounded-3xl bg-white/95 p-8 shadow-2xl ring-1 ring-indigo-100 backdrop-blur-sm","children":[["$","div",null,{"className":"flex flex-col gap-4 sm:flex-row sm:items-center sm:justify-between","children":[["$","h2",null,{"className":"text-4xl font-extrabold tracking-tight text-gray-900","children":"Workshop Programme (Half‑day)"}],["$","span",null,{"className":"inline-flex items-center gap-2 self-start rounded-full bg-indigo-600/10 px-4 py-2 text-sm font-semibold text-indigo-700 ring-1 ring-indigo-200","children":[["$","svg",null,{"className":"h-4 w-4","xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","stroke":"currentColor","strokeWidth":"1.5","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M8.25 6.75h7.5M8.25 10.5h7.5m-7.5 3.75h4.5m7.5-1.5A2.25 2.25 0 0 1 19.5 18v1.5A2.25 2.25 0 0 1 17.25 21H6.75A2.25 2.25 0 0 1 4.5 18.75V18a2.25 2.25 0 0 1 2.25-2.25h12.75Zm0-9.75V6A2.25 2.25 0 0 1 19.5 8.25H4.5A2.25 2.25 0 0 1 2.25 6V4.5A2.25 2.25 0 0 1 4.5 2.25h15A2.25 2.25 0 0 1 21.75 4.5V6Z"}]}],"Room 306B · 19 Oct 2025"]}]]}],["$","div",null,{"className":"mt-6 overflow-x-auto","children":["$","table",null,{"className":"w-full min-w-[640px] text-left text-base text-gray-900","children":[["$","thead",null,{"className":"bg-indigo-600/90 text-white","children":["$","tr",null,{"children":[["$","th",null,{"className":"whitespace-nowrap px-6 py-3 text-lg font-semibold tracking-wide","children":"Time"}],["$","th",null,{"className":"px-6 py-3 text-lg font-semibold tracking-wide","children":"Session"}]]}]}],["$","tbody",null,{"className":"divide-y divide-indigo-100","children":[["$","tr","0",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"09:00 – 09:30"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"font-semibold text-gray-900","children":"Opening Remarks"}],false]}]}]]}],["$","tr","1",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"09:30 – 10:05"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800","children":[["$","span",null,{"className":"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700","children":"Keynote"}],"Bernard Ghanem — Towards Robust Multimodal Egocentric Video Understanding"]}],false]}]}]]}],["$","tr","2",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"10:05 – 10:40"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800","children":[["$","span",null,{"className":"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700","children":"Keynote"}],"Dima Damen — Video Understanding Out of the Frame: An Egocentric Perspective"]}],false]}]}]]}],["$","tr","3",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"10:40 – 11:00"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"font-semibold text-gray-900","children":"Break & Poster Session"}],false]}]}]]}],["$","tr","4",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"11:00 – 11:45"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[false,["$","div",null,{"className":"space-y-4 text-sm text-gray-700 md:text-base","children":[["$","span",null,{"className":"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700","children":"Invited Paper Presentations"}],["$","ul",null,{"className":"space-y-1 leading-relaxed","children":[["$","li","0",{"className":"space-y-1","children":[["$","a",null,{"href":"https://red-fairy.github.io/argus/","target":"_blank","rel":"noopener noreferrer","className":"font-semibold text-amber-700 hover:text-amber-800 hover:underline","children":"Beyond the Frame: Generating 360° Panoramic Videos from Perspective Videos"}],["$","div",null,{"className":"text-sm italic text-gray-600 md:text-base","children":"Presenter: Rundong Luo"}]]}],["$","li","1",{"className":"space-y-1","children":[["$","a",null,{"href":"https://schowdhury671.github.io/egoadapt_project/","target":"_blank","rel":"noopener noreferrer","className":"font-semibold text-amber-700 hover:text-amber-800 hover:underline","children":"EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception"}],["$","div",null,{"className":"text-sm italic text-gray-600 md:text-base","children":"Presenter: Sanjoy Chowdhury"}]]}],["$","li","2",{"className":"space-y-1","children":[["$","a",null,{"href":"https://vision.cs.utexas.edu/projects/switch_a_view/","target":"_blank","rel":"noopener noreferrer","className":"font-semibold text-amber-700 hover:text-amber-800 hover:underline","children":"Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos"}],["$","div",null,{"className":"text-sm italic text-gray-600 md:text-base","children":"Presenter: Sagnik Majumder"}]]}]]}]]}]]}]}]]}],["$","tr","5",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"11:45 – 12:20"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"inline-flex items-baseline gap-2 whitespace-nowrap font-semibold text-indigo-800","children":[["$","span",null,{"className":"rounded-full bg-indigo-600/15 px-2 py-1 text-xs font-bold uppercase tracking-wide text-indigo-700","children":"Keynote"}],"Addison Lin Wang — 360 Vision in the Foundation AI Era: Principles, Methods, and Future Directions"]}],false]}]}]]}],["$","tr","6",{"className":"odd:bg-white even:bg-indigo-50/40 align-top","children":[["$","td",null,{"className":"whitespace-nowrap px-6 py-4 text-lg font-semibold text-indigo-700","children":"12:20 – 12:35"}],["$","td",null,{"className":"px-6 py-4 align-top text-base text-gray-900","children":["$","div",null,{"className":"space-y-4","children":[["$","span",null,{"className":"font-semibold text-gray-900","children":"Awards Ceremony & Concluding Remarks"}],false]}]}]]}]]}]]}]}]]}]}],["$","section",null,{"id":"challenge","className":"mx-auto mt-24 max-w-6xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"BinEgo‑360° Challenge"}],["$","p",null,{"className":"mt-6 text-gray-700","children":["The challenge uses our public dataset ",["$","a",null,{"href":"https://x360dataset.github.io/","target":"_blank","rel":"noreferrer","className":"underline","children":"360+x"}]," for training/validation, and a held-out test set for the evaluation. ",["$","ul",null,{"children":"Apart from the prizes, winners of the challenge will be invited to submit a paper/report to be included in the workshop proceedings and present at the workshop."}]," For more details about the dataset, tracks, timeline, and submission rules, please see below:"]}],["$","div",null,{"className":"mt-6 rounded border-l-4 border-yellow-400 bg-yellow-50 p-4 text-gray-700","children":[["$","p",null,{"className":"font-semibold","children":"Important Notice:"}],["$","p",null,{"className":"mt-2","children":["$","b",null,{"children":"New Final Submission Deadline  ▶  20 August 2025 (AOE)"}]}],["$","p",null,{"className":"mt-2","children":"We are delighted to let you know that the challenge deadline has been extended! Now you have more time to cook your good stuff!"}]]}]]}],["$","section",null,{"id":"dataset","className":"mx-auto mt-24 max-w-6xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Dataset Overview"}],["$","div",null,{"className":"mt-8 grid gap-8 md:grid-cols-2","children":[["$","div",null,{"className":"w-full h-[400px] overflow-hidden rounded-lg shadow-md","children":["$","img",null,{"src":"https://x360dataset.github.io/static/images/overall.gif","alt":"Dataset montage","className":"w-full h-full object-cover"}]}],["$","div",null,{"className":"flex flex-col justify-center text-gray-700","children":[["$","ul",null,{"className":"space-y-3","children":[["$","li",null,{"children":"2,152 videos – 8.579 M frames / 67.78 h."}],["$","li",null,{"children":[["$","strong",null,{"children":"Viewpoints"}],": 360° panoramic, binocular & monocular egocentric, third‑person front."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Modalities"}],": RGB video, 6‑channel spatial audio, GPS + weather, text scene description."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Annotations"}],": 38 action classes, temporal segments; object bounding boxes."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Resolution"}],": 5 K originals (5 760 × 2 880 pano)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"License"}],": CC BY‑NC‑SA 4.0. All faces auto‑blurred."]}]]}],["$","div",null,{"className":"mt-6 flex flex-wrap gap-4","children":[["$","a",null,{"href":"https://huggingface.co/datasets/quchenyuan/360x_dataset_HR","className":"rounded bg-gray-800 px-4 py-2 text-sm font-medium text-white hover:bg-gray-900","children":"Download HR"}],["$","a",null,{"href":"https://huggingface.co/datasets/quchenyuan/360x_dataset_LR","className":"rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400","children":"Download LR"}],["$","a",null,{"href":"https://arxiv.org/abs/2404.00989","className":"rounded border border-indigo-600 bg-indigo-50 px-4 py-2 text-sm font-medium text-indigo-700 hover:bg-indigo-100","children":"Paper (CVPR 2024)"}],["$","a",null,{"href":"https://github.com/x360dataset/x360dataset-kit","className":"rounded border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 hover:border-gray-400","children":"Baseline Code"}]]}]]}]]}]]}],["$","section",null,{"id":"tracks","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Challenge Tracks & Baselines"}],["$","div",null,{"className":"mt-10 grid gap-20 md:grid-cols-2","children":[["$","div",null,{"className":"flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-indigo-600","children":"1 · Classification"}],["$","p",null,{"className":"mt-2 text-gray-600","children":"Predict the scene label for a whole clip. We follow the scene categories provided in the dataset."}],["$","ul",null,{"className":"mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Input"}],": 360° RGB + egocentric RGB + audio/binaural delay."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Output"}],": The scene label."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Metric"}],": Top‑1 Accuracy (in test set)."]}]]}]]}],["$","div",null,{"className":"mt-6 rounded bg-gray-50 p-4 text-sm","children":[["$","p",null,{"className":"font-medium","children":"Baseline (All views and modalities use)"}],["$","p",null,{"children":["Top‑1 Acc: ",["$","span",null,{"className":"font-semibold","children":"80.62  %"}]]}]]}],["$","div",null,{"className":"mt-8 text-center","children":["$","a",null,{"href":"https://www.kaggle.com/competitions/bin-ego-360-challenge-classification-ext","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"h-5 w-5","fill":"currentColor","children":["$","path",null,{"d":"M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z"}]}],"Join on Kaggle"]}]}]]}],["$","div",null,{"className":"flex flex-col justify-between rounded-xl border border-gray-200 bg-white p-6 shadow-sm","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-indigo-600","children":"2 · Temporal Action Localization"}],["$","p",null,{"className":"mt-2 text-gray-600","children":"Detect the start and end time of every action instance inside a clip."}],["$","ul",null,{"className":"mt-4 list-disc space-y-1 pl-5 text-sm text-gray-700","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Input"}],": Same modalities as Track 1"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Output"}],": JSON output for each detection:",["$","code",null,{"children":"{\"video_id\": ..., \"t_start\": ..., \"t_end\": ..., \"label\": ...}"}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Metric"}],": mAP averaged over IoU ∈ ","{0.5, 0.75, 0.95}","."]}]]}]]}],["$","div",null,{"className":"mt-6 rounded bg-gray-50 p-4 text-sm","children":[["$","p",null,{"className":"font-medium mb-2","children":"Baseline (TriDet + VAD)"}],["$","table",null,{"className":"w-full text-sm text-left text-gray-700 border border-gray-200 rounded","children":[["$","thead",null,{"className":"bg-gray-100","children":["$","tr",null,{"children":[["$","th",null,{"className":"px-3 py-2 border-b","children":"Metric"}],["$","th",null,{"className":"px-3 py-2 border-b","children":"Score"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"className":"px-3 py-2 border-b","children":"mAP@0.5"}],["$","td",null,{"className":"px-3 py-2 border-b font-semibold","children":"27.1"}]]}],["$","tr",null,{"children":[["$","td",null,{"className":"px-3 py-2 border-b","children":"mAP@0.75"}],["$","td",null,{"className":"px-3 py-2 border-b font-semibold","children":"18.7"}]]}],["$","tr",null,{"children":[["$","td",null,{"className":"px-3 py-2 border-b","children":"mAP@0.95"}],["$","td",null,{"className":"px-3 py-2 border-b font-semibold","children":"7.0"}]]}],["$","tr",null,{"children":[["$","td",null,{"className":"px-3 py-2","children":"Average"}],["$","td",null,{"className":"px-3 py-2 font-semibold","children":"17.6"}]]}]]}]]}]]}],["$","div",null,{"className":"mt-8 text-center","children":["$","a",null,{"href":"https://www.kaggle.com/competitions/bin-ego-360-challenge-tal-ext","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-2 rounded-lg bg-sky-500 px-6 py-3 text-white shadow hover:bg-sky-600 transition","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"h-5 w-5","fill":"currentColor","children":["$","path",null,{"d":"M4 4h4v7.586l8.293-8.293 2.414 2.414L10.414 14l8.293 8.293-2.414 2.414L8 16.414V24H4V4z"}]}],"Join on Kaggle"]}]}]]}]]}]]}],["$","section",null,{"id":"timeline","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Timeline (Anywhere on Earth)"}],["$","ol",null,{"className":"mt-8 border-l-2 border-indigo-600","children":[["$","li","0",{"className":"relative ml-6 pb-8 last:pb-0","children":[["$","span",null,{"className":"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"}],["$","span",null,{"className":"font-medium text-gray-900","children":"1 Jun 2025"}],["$","span",null,{"className":"ml-2 text-gray-600","children":"Dataset & baselines release; Kaggle opens"}]]}],["$","li","1",{"className":"relative ml-6 pb-8 last:pb-0","children":[["$","span",null,{"className":"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"}],["$","span",null,{"className":"font-medium text-gray-900","children":"20 Aug 2025"}],["$","span",null,{"className":"ml-2 text-gray-600","children":"Submission deadline"}]]}],["$","li","2",{"className":"relative ml-6 pb-8 last:pb-0","children":[["$","span",null,{"className":"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"}],["$","span",null,{"className":"font-medium text-gray-900","children":"Sep 2025"}],["$","span",null,{"className":"ml-2 text-gray-600","children":"Technical report and poster due"}]]}],["$","li","3",{"className":"relative ml-6 pb-8 last:pb-0","children":[["$","span",null,{"className":"absolute -left-3 top-1.5 h-2 w-2 rounded-full bg-indigo-600"}],["$","span",null,{"className":"font-medium text-gray-900","children":"19-20 Oct 2025"}],["$","span",null,{"className":"ml-2 text-gray-600","children":"Awards & talks at ICCV 2025 workshop"}]]}]]}]]}],["$","section",null,{"id":"submission","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Submission Rules"}],["$","ol",null,{"className":"mt-6 list-decimal space-y-3 pl-6 text-gray-700","children":[["$","li",null,{"children":"Teams (≤  5 members) register on Kaggle and fill in the team form."}],["$","li",null,{"children":["Up to ",["$","strong",null,{"children":"5 submissions per track per team"}]," – the last one counts."]}],["$","li",null,{"children":"The winners need to submit a technical report and a poster to be presented at the workshop"}],["$","li",null,{"children":"No external data that overlaps with the hidden test clips."}],["$","li",null,{"children":"Any submission after the deadline will not be considered."}]]}]]}],["$","section",null,{"id":"prizes","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Prizes & Sponsors"}],["$","ul",null,{"className":"mt-6 space-y-2 text-gray-700","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Hardware:"}]," Insta360 X5 panoramic camera (",["$","a",null,{"href":"https://www.insta360.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Insta360"}],")"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Compute:"}]," GPU Cloud Credit (worth £5-15k) (",["$","a",null,{"href":"https://www.scan.co.uk/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"SCAN"}],")"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Gift:"}]," Amazon / Taobao vouchers (",["$","a",null,{"href":"https://www.allsee-tech.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Allsee"}],")"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Registration:"}]," Workshop fee for the 1st & 2nd winners on each track (",["$","a",null,{"href":"https://www.tencent.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Tencent"}],")"]}]]}],["$","p",null,{"className":"mt-4 text-gray-700","children":["Sponsored by ",["$","a",null,{"href":"https://www.insta360.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Insta360"}]," · ",["$","a",null,{"href":"https://www.scan.co.uk/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"SCAN"}]," · ",["$","a",null,{"href":"https://www.allsee-tech.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Allsee"}]," · ",["$","a",null,{"href":"https://www.tencent.com/","target":"_blank","rel":"noreferrer","className":"text-indigo-600 hover:underline","children":"Tencent"}]]}]]}],["$","section",null,{"className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Ethics & Broader Impact"}],["$","p",null,{"className":"mt-4 text-gray-700","children":"All videos were recorded in public or non‑sensitive areas with informed participant consent. Faces are automatically blurred, and the dataset is released for non‑commercial research under CC BY‑NC‑SA 4.0. We prohibit any re‑identification, surveillance or commercial use. By advancing robust multi‑modal perception, we aim to benefit robotics, AR/VR and assistive tech while upholding fairness and privacy."}]]}],["$","section",null,{"id":"organizers","className":"mx-auto mt-24 max-w-4xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Organisers"}],["$","div",null,{"className":"mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4","children":[["$","div","Jianbo Jiao",{"className":"text-center","children":[["$","a",null,{"href":"https://jianbojiao.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/jiao.jpg","alt":"Jianbo Jiao","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://jianbojiao.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Jianbo Jiao"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Birmingham"}]]}],["$","div","Shangzhe Wu",{"className":"text-center","children":[["$","a",null,{"href":"https://elliottwu.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/wu.jpg","alt":"Shangzhe Wu","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://elliottwu.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Shangzhe Wu"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Cambridge"}]]}],["$","div","Dylan Campbell",{"className":"text-center","children":[["$","a",null,{"href":"https://sites.google.com/view/djcampbell","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/campbell.jpg","alt":"Dylan Campbell","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://sites.google.com/view/djcampbell","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Dylan Campbell"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"Australian National University"}]]}],["$","div","Yunchao Wei",{"className":"text-center","children":[["$","a",null,{"href":"https://weiyc.github.io/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/wei.jpg","alt":"Yunchao Wei","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://weiyc.github.io/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Yunchao Wei"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"Beijing Jiaotong University"}]]}],["$","div","Lu Qi",{"className":"text-center","children":[["$","a",null,{"href":"http://luqi.info/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/qi.jpg","alt":"Lu Qi","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"http://luqi.info/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Lu Qi"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"Insta360"}]]}],["$","div","Yasmine Mellah",{"className":"text-center","children":[["$","a",null,{"href":"https://www.audioscenic.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/placeholder_female.jpg","alt":"Yasmine Mellah","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://www.audioscenic.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Yasmine Mellah"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"Audioscenic"}]]}],["$","div","Aleš Leonardis",{"className":"text-center","children":[["$","a",null,{"href":"https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/leonardis.jpg","alt":"Aleš Leonardis","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/leonardis-ales","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Aleš Leonardis"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Birmingham"}]]}]]}],["$","p",null,{"className":"mt-8 text-gray-700","children":["$","span",null,{"className":"font-semibold","children":"Technical Committee:"}]}],["$","div",null,{"className":"mt-8 grid gap-8 md:grid-cols-3 lg:grid-cols-4","children":[["$","div","Chenyuan Qu",{"className":"text-center","children":[["$","a",null,{"href":"https://chenyuanqu.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/chenyuan.jpg","alt":"Chenyuan Qu","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://chenyuanqu.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Chenyuan Qu"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Birmingham"}]]}],["$","div","Han Hu",{"className":"text-center","children":[["$","a",null,{"href":"https://scholar.google.com/Publicationss?hl=zh-CN&view_op=list_works&gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4&user=UJRtTJ0AAAAJ","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/han.jpg","alt":"Han Hu","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://scholar.google.com/Publicationss?hl=zh-CN&view_op=list_works&gmla=ALUCkoXDRY1FyBSlDC4q0bpK9zpnxnhaf2PzJqv2dgVESTCALg71TCdFa7PGpFqiTrWvhnZalzAY234KBYkLCs4O7U4&user=UJRtTJ0AAAAJ","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Han Hu"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Birmingham"}]]}],["$","div","Qiming Huang",{"className":"text-center","children":[["$","a",null,{"href":"https://qiming-huang.github.io/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/qiming.jpg","alt":"Qiming Huang","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://qiming-huang.github.io/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Qiming Huang"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Birmingham"}]]}],["$","div","Hao Chen",{"className":"text-center","children":[["$","a",null,{"href":"https://h-chen.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/organizers/hao.jpg","alt":"Hao Chen","className":"mx-auto h-28 w-28 rounded-full object-cover shadow-md hover:shadow-lg"}]}],["$","h3",null,{"className":"mt-3 text-base font-semibold text-gray-900","children":["$","a",null,{"href":"https://h-chen.com/","target":"_blank","rel":"noreferrer","className":"hover:underline","children":"Hao Chen"}]}],["$","p",null,{"className":"text-sm text-gray-600","children":"University of Cambridge"}]]}]]}],["$","p",null,{"className":"mt-4 text-gray-700","children":["Contact: ",["$","a",null,{"href":"mailto:j.jiao@bham.ac.uk","className":"text-indigo-600 hover:underline","children":"j.jiao@bham.ac.uk"}]]}]]}],["$","section",null,{"id":"sponsors","className":"mx-auto mt-24 max-w-10xl px-4 text-center","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Sponsors"}],["$","p",null,{"className":"mt-6 text-gray-700","children":"We gratefully acknowledge the generous support of our sponsors."}],["$","div",null,{"className":"mt-10 flex flex-wrap justify-center gap-10","children":[["$","a",null,{"href":"https://www.insta360.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/insta360-logo.png","alt":"Insta360","className":"h-24 object-contain"}]}],["$","a",null,{"href":"https://www.scan.co.uk/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/SCAN-logo.png","alt":"SCAN","className":"h-24 object-contain"}]}],["$","a",null,{"href":"https://www.allsee-tech.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/allsee-logo.jpg","alt":"Allsee","className":"h-24 object-contain"}]}],["$","a",null,{"href":"https://www.tencent.com/","target":"_blank","rel":"noreferrer","children":["$","img",null,{"src":"/BinEgo-360/tencent_logo.png","alt":"Tencent","className":"h-24 object-contain"}]}]]}]]}],["$","section",null,{"className":"mx-auto mt-24 max-w-3xl px-4","children":[["$","h2",null,{"className":"text-3xl font-bold text-gray-900","children":"Publication(s)"}],["$","p",null,{"className":"mt-4 text-gray-700","children":"If you use the 360+x dataset or participate in the challenge, please consider cite:"}],["$","pre",null,{"className":"mt-4 rounded bg-gray-100 p-4 text-sm leading-tight text-gray-800 overflow-x-auto","children":"@inproceedings{chen2024x360,\n  title     = {360+x: A Panoptic Multi-modal Scene Understanding Dataset},\n  author    = {Chen, Hao and Hou, Yuqi and Qu, Chenyuan and Testini, Irene and Hong, Xiaohan and Jiao, Jianbo},\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  year      = {2024}\n}"}]]}],["$","footer",null,{"className":"mt-32 bg-gray-50 py-6 text-center text-sm text-gray-600","children":["$","p",null,{"children":["© ",2025," BinEgo‑360° Workshop. Built with Next.js & Tailwind CSS. Hosted on GitHub Pages."]}]}]]}]],["$","$L4",null,{"children":"$L5"}],null,["$","$L6",null,{"children":["$L7","$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","Dn3whDzG-xjS11hN-dYjR",{"children":[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],null]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
e:"$Sreact.suspense"
f:I[4911,[],"AsyncMetadata"]
5:["$","$e",null,{"fallback":null,"children":["$","$Lf",null,{"promise":"$@10"}]}]
8:null
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
10:{"metadata":[["$","title","0",{"children":"BinEgo‑360 Challenge"}],["$","meta","1",{"name":"description","content":"The BinEgo‑360 Challenge targets human‑like perception by jointly reasoning over 360° panoramic and binocular egocentric video streams, aligned with spatial audio, text and geo‑metadata."}],["$","link","2",{"rel":"icon","href":"/BinEgo-360/favicon.ico","type":"image/x-icon","sizes":"256x256"}]],"error":null,"digest":"$undefined"}
a:{"metadata":"$10:metadata","error":null,"digest":"$undefined"}
